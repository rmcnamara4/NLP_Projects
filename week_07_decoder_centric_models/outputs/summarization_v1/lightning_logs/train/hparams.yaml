model_cfg:
  model_name: gpt2
  attn_pdrop: 0.3
  resid_pdrop: 0.3
  embd_pdrop: 0.3
  gradual_unfreeze: true
optimizer_cfg:
  _target_: torch.optim.AdamW
  lr: 0.0001
  weight_decay: 0.01
scheduler_cfg:
  _target_: torch.optim.lr_scheduler.CosineAnnealingLR
  T_max: 10
  eta_min: 0.0
