model_cfg:
  model_name: gpt2
  attn_pdrop: 0.1
  resid_pdrop: 0.1
  embd_pdrop: 0.1
  gradual_unfreeze: false
optimizer_cfg:
  _target_: torch.optim.AdamW
  lr: 0.0003
  weight_decay: 0.001
scheduler_cfg:
  _target_: torch.optim.lr_scheduler.CosineAnnealingLR
  T_max: 10
  eta_min: 0.0
