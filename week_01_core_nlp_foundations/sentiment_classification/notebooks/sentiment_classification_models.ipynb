{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmggF5bRhcUJ"
      },
      "source": [
        "# Model Evaluation - Sentiment Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njDxgmVyHpCb"
      },
      "source": [
        "> **Note**: This notebook is compatible with both Google Colab and local Jupyter environments. Colab-specific sections are clearly marked."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PH9jz_0_d-2e"
      },
      "source": [
        "This notebook demonstrates the training and evaluation of traditional machine learning models for **sentiment analysis** on the Amazon Reviews dataset. After preprocessing text in a separate pipeline, we use **TF-IDF vectorization** to extract features and train models including Logistic Regression, XGBoost, LightGBM, and CatBoost. We apply **Optuna** for hyperparameter optimization and **MLflow** for experiment tracking.\n",
        "\n",
        "Key components covered:\n",
        "- TF-IDF feature extraction from preprocessed text\n",
        "- Hyperparameter tuning with Optuna\n",
        "- Evaluation using metrics such as accuracy, precision, recall, F1, AUROC, and AUPRC\n",
        "- Confusion matrix, ROC and PR curve visualizations\n",
        "- End-to-end pipeline logging and model versioning with MLflow\n",
        "\n",
        "This project is part of my Week 1 exploration of **core NLP foundations**, and provides a strong baseline for future comparisons with neural and transformer-based models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fn-Sa2aoivcC"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYOQqH1Pi7hP",
        "outputId": "bd0ea9ee-edc3-4c21-9853-34d9bc89f3eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: xgboost==2.1.4 in /usr/local/lib/python3.11/dist-packages (2.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xgboost==2.1.4) (2.0.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost==2.1.4) (2.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost==2.1.4) (1.15.2)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.11/dist-packages (4.5.0)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from lightgbm) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from lightgbm) (1.15.2)\n",
            "Collecting optuna\n",
            "  Downloading optuna-4.3.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.15.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.40)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.13.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.1)\n",
            "Downloading optuna-4.3.0-py3-none-any.whl (386 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.6/386.6 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.15.2-py3-none-any.whl (231 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.9/231.9 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, alembic, optuna\n",
            "Successfully installed alembic-1.15.2 colorlog-6.9.0 optuna-4.3.0\n",
            "Collecting catboost\n",
            "  Downloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from catboost) (1.15.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (9.1.2)\n",
            "Downloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.8\n",
            "Collecting swifter\n",
            "  Downloading swifter-1.4.0.tar.gz (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from swifter) (2.2.2)\n",
            "Requirement already satisfied: psutil>=5.6.6 in /usr/local/lib/python3.11/dist-packages (from swifter) (5.9.5)\n",
            "Requirement already satisfied: dask>=2.10.0 in /usr/local/lib/python3.11/dist-packages (from dask[dataframe]>=2.10.0->swifter) (2024.12.1)\n",
            "Requirement already satisfied: tqdm>=4.33.0 in /usr/local/lib/python3.11/dist-packages (from swifter) (4.67.1)\n",
            "Requirement already satisfied: click>=8.1 in /usr/local/lib/python3.11/dist-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (8.1.8)\n",
            "Requirement already satisfied: cloudpickle>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (3.1.1)\n",
            "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.11/dist-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (24.2)\n",
            "Requirement already satisfied: partd>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (1.4.2)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (6.0.2)\n",
            "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (0.12.1)\n",
            "Requirement already satisfied: importlib_metadata>=4.13.0 in /usr/local/lib/python3.11/dist-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (8.7.0)\n",
            "Requirement already satisfied: dask-expr<1.2,>=1.1 in /usr/local/lib/python3.11/dist-packages (from dask[dataframe]>=2.10.0->swifter) (1.1.21)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->swifter) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->swifter) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->swifter) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->swifter) (2025.2)\n",
            "Requirement already satisfied: pyarrow>=14.0.1 in /usr/local/lib/python3.11/dist-packages (from dask-expr<1.2,>=1.1->dask[dataframe]>=2.10.0->swifter) (18.1.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata>=4.13.0->dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (3.21.0)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.11/dist-packages (from partd>=1.4.0->dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (1.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->swifter) (1.17.0)\n",
            "Building wheels for collected packages: swifter\n",
            "  Building wheel for swifter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for swifter: filename=swifter-1.4.0-py3-none-any.whl size=16505 sha256=ec64736cf535045f935838e1e09ef95961cca787a8d25e8416395f08d3394464\n",
            "  Stored in directory: /root/.cache/pip/wheels/ef/7f/bd/9bed48f078f3ee1fa75e0b29b6e0335ce1cb03a38d3443b3a3\n",
            "Successfully built swifter\n",
            "Installing collected packages: swifter\n",
            "Successfully installed swifter-1.4.0\n",
            "Collecting optuna-integration\n",
            "  Downloading optuna_integration-4.3.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (from optuna-integration) (4.3.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna->optuna-integration) (1.15.2)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna->optuna-integration) (6.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna->optuna-integration) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna->optuna-integration) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna->optuna-integration) (2.0.40)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna->optuna-integration) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna->optuna-integration) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna->optuna-integration) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna->optuna-integration) (4.13.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna->optuna-integration) (3.2.1)\n",
            "Downloading optuna_integration-4.3.0-py3-none-any.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.5/98.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: optuna-integration\n",
            "Successfully installed optuna-integration-4.3.0\n",
            "Collecting mlflow\n",
            "  Downloading mlflow-2.22.0-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting mlflow-skinny==2.22.0 (from mlflow)\n",
            "  Downloading mlflow_skinny-2.22.0-py3-none-any.whl.metadata (31 kB)\n",
            "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.1.0)\n",
            "Requirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.1.6)\n",
            "Requirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.15.2)\n",
            "Collecting docker<8,>=4.0.0 (from mlflow)\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting graphene<4 (from mlflow)\n",
            "  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting gunicorn<24 (from mlflow)\n",
            "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.8)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.0.2)\n",
            "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.2.2)\n",
            "Requirement already satisfied: pyarrow<20,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (18.1.0)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.6.1)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.15.2)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.0.40)\n",
            "Requirement already satisfied: cachetools<6,>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (8.1.8)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (3.1.1)\n",
            "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==2.22.0->mlflow)\n",
            "  Downloading databricks_sdk-0.52.0-py3-none-any.whl.metadata (39 kB)\n",
            "Collecting fastapi<1 (from mlflow-skinny==2.22.0->mlflow)\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (3.1.44)\n",
            "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (8.7.0)\n",
            "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (1.16.0)\n",
            "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (1.16.0)\n",
            "Requirement already satisfied: packaging<25 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (24.2)\n",
            "Requirement already satisfied: protobuf<7,>=3.12.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (5.29.4)\n",
            "Requirement already satisfied: pydantic<3,>=1.10.8 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (2.11.4)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (2.32.3)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (0.5.3)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (4.13.2)\n",
            "Collecting uvicorn<1 (from mlflow-skinny==2.22.0->mlflow)\n",
            "  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic!=1.10.0,<2->mlflow) (1.1.3)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from docker<8,>=4.0.0->mlflow) (2.4.0)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (3.1.3)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (2.2.0)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (1.9.0)\n",
            "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_core-3.2.6-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from graphene<4->mlflow) (2.9.0.post0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2<4,>=2.11->mlflow) (3.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (3.2.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3->mlflow) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3->mlflow) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2->mlflow) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2->mlflow) (3.6.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.2.1)\n",
            "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.11/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow) (2.38.0)\n",
            "Collecting starlette<0.47.0,>=0.40.0 (from fastapi<1->mlflow-skinny==2.22.0->mlflow)\n",
            "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.22.0->mlflow) (4.0.12)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.22.0->mlflow) (3.21.0)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.22.0->mlflow) (1.2.18)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.22.0->mlflow) (75.2.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.37b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.22.0->mlflow) (0.37b0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.22.0->mlflow) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.22.0->mlflow) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.22.0->mlflow) (0.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.22.0->mlflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.22.0->mlflow) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.22.0->mlflow) (2025.4.26)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn<1->mlflow-skinny==2.22.0->mlflow) (0.16.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.22.0->mlflow) (1.17.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.22.0->mlflow) (5.0.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow) (4.9.1)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==2.22.0->mlflow) (4.9.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==2.22.0->mlflow) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow) (0.6.1)\n",
            "Downloading mlflow-2.22.0-py3-none-any.whl (29.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.0/29.0 MB\u001b[0m \u001b[31m92.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlflow_skinny-2.22.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m117.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading databricks_sdk-0.52.0-py3-none-any.whl (700 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m700.2/700.2 kB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_core-3.2.6-py3-none-any.whl (203 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.4/203.4 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
            "Downloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: uvicorn, gunicorn, graphql-core, starlette, graphql-relay, docker, graphene, fastapi, databricks-sdk, mlflow-skinny, mlflow\n",
            "Successfully installed databricks-sdk-0.52.0 docker-7.1.0 fastapi-0.115.12 graphene-3.4.3 graphql-core-3.2.6 graphql-relay-3.2.0 gunicorn-23.0.0 mlflow-2.22.0 mlflow-skinny-2.22.0 starlette-0.46.2 uvicorn-0.34.2\n"
          ]
        }
      ],
      "source": [
        "!pip install xgboost==2.1.4\n",
        "!pip install lightgbm\n",
        "!pip install optuna\n",
        "!pip install catboost\n",
        "!pip install swifter\n",
        "!pip install optuna-integration\n",
        "!pip install mlflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99wlPov1kC40",
        "outputId": "e9f2ae01-905f-443c-ddbd-87d27fd95d57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "if 'google.colab' in sys.modules:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    project_path = '/content/drive/MyDrive/NLP_Projects/Week_1/sentiment-analysis/'\n",
        "    if os.path.exists(project_path):\n",
        "        os.chdir(project_path)\n",
        "        print(f\"Changed working directory to: {project_path}\")\n",
        "    else:\n",
        "        raise FileNotFoundError(f\"Project path not found: {project_path}\")\n",
        "else:\n",
        "    print(\"Not running in Colab — skipping Drive mount.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hf5K9R7AhElU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "import swifter\n",
        "\n",
        "import optuna\n",
        "from optuna.integration import XGBoostPruningCallback, LightGBMPruningCallback, CatBoostPruningCallback\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, average_precision_score, confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc, precision_recall_curve\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import pickle\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import mlflow\n",
        "mlflow.autolog(disable = True)\n",
        "\n",
        "import ast"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXMhlctwj1ya"
      },
      "source": [
        "## Loading and Cleaning the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJyk5rYBXeBr"
      },
      "source": [
        "We begin by loading the pre-split text datasets for training, validation, and testing. The .squeeze() method is used to ensure the data is stored as a 1D pandas.Series rather than a DataFrame with a single column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWsTWvvEjwyw"
      },
      "outputs": [],
      "source": [
        "X_train = pd.read_csv('./data/X_train_nltk.csv').squeeze()\n",
        "X_val = pd.read_csv('./data/X_val_nltk.csv').squeeze()\n",
        "X_test = pd.read_csv('./data/X_test_nltk.csv').squeeze()\n",
        "\n",
        "y_train = pd.read_csv('./data/y_train.csv').squeeze()\n",
        "y_val = pd.read_csv('./data/y_val.csv').squeeze()\n",
        "y_test = pd.read_csv('./data/y_test.csv').squeeze()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzxKmnPAXls_"
      },
      "source": [
        "Since some rows may be missing values, we filter out any entries in X that are NaN, and remove the corresponding labels from y to ensure alignment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nk75s7O-XhbE"
      },
      "outputs": [],
      "source": [
        "inds = X_train.isna()\n",
        "X_train = X_train[~inds]\n",
        "y_train = y_train[~inds]\n",
        "\n",
        "inds = X_val.isna()\n",
        "X_val = X_val[~inds]\n",
        "y_val = y_val[~inds]\n",
        "\n",
        "inds = X_test.isna()\n",
        "X_test = X_test[~inds]\n",
        "y_test = y_test[~inds]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7kX-8wrpIs2"
      },
      "source": [
        "## End-to-End Model Training, Tuning, and Evaluation with Optuna and MLFlow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_tqv9lfazIO"
      },
      "source": [
        "In this section, we define a full ML pipeline that includes:\n",
        "\n",
        "- Constructing and tuning a TF-IDF + classifier pipeline using Optuna\n",
        "\n",
        "- Logging hyperparameters, metrics, and artifacts to MLflow for experiment tracking\n",
        "\n",
        "- Evaluating the best model on train, validation, and test sets\n",
        "\n",
        "- Visualizing performance via ROC/PR curves and confusion matrices\n",
        "\n",
        "Each component is modular and supports Logistic Regression, XGBoost, LightGBM, and CatBoost. This setup enables reproducibility and scalable experimentation for binary classification tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8Qb5XhJqpYM"
      },
      "outputs": [],
      "source": [
        "def create_model(model_name, model_params):\n",
        "  \"\"\"\n",
        "  Creates and returns a classification model based on the specified model name and hyperparameters.\n",
        "\n",
        "  Args:\n",
        "      model_name (str): The name of the model to create. One of:\n",
        "          - 'lr'   : Logistic Regression\n",
        "          - 'xgb'  : XGBoost Classifier\n",
        "          - 'lgbm' : LightGBM Classifier\n",
        "          - 'cat'  : CatBoost Classifier\n",
        "      model_params (dict): Dictionary of hyperparameters to initialize the model with.\n",
        "\n",
        "  Returns:\n",
        "      model (sklearn/base.BaseEstimator): An instance of the specified classification model,\n",
        "                                          initialized with the provided parameters.\n",
        "\n",
        "  Notes:\n",
        "      - Adds default settings for `n_jobs` or `thread_count` where applicable for parallelism.\n",
        "      - Evaluation metric is preset to AUC for tree-based models.\n",
        "  \"\"\"\n",
        "  if model_name == 'lr':\n",
        "    model = LogisticRegression(**model_params, n_jobs = 5)\n",
        "  elif model_name == 'xgb':\n",
        "    model = XGBClassifier(**model_params, eval_metric = 'auc', n_jobs = 5)\n",
        "  elif model_name == 'lgbm':\n",
        "    model = LGBMClassifier(**model_params, metric = 'auc', n_jobs = 5)\n",
        "  elif model_name == 'cat':\n",
        "    model = CatBoostClassifier(**model_params, eval_metric = 'AUC', thread_count = 5)\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kUMdAHPAW5ok"
      },
      "outputs": [],
      "source": [
        "def calculate_metrics(y_true, y_pred_proba, y_pred, set = 'train'):\n",
        "  \"\"\"\n",
        "  Calculates common classification evaluation metrics.\n",
        "\n",
        "  Args:\n",
        "      y_true (array-like): Ground truth binary labels (0 or 1).\n",
        "      y_pred_proba (array-like): Predicted probabilities for the positive class.\n",
        "      y_pred (array-like): Predicted binary class labels.\n",
        "      set (str, optional): Identifier for the dataset split (e.g., 'train', 'val', 'test').\n",
        "                            Used to prefix the returned metric keys. Default is 'train'.\n",
        "\n",
        "  Returns:\n",
        "      dict: A dictionary containing the following metrics with keys prefixed by `set`:\n",
        "          - accuracy: Proportion of correct predictions.\n",
        "          - precision: Proportion of positive predictions that are correct.\n",
        "          - recall: Proportion of actual positives correctly predicted.\n",
        "          - specificity: Proportion of actual negatives correctly predicted.\n",
        "          - f1: Harmonic mean of precision and recall.\n",
        "          - auroc: Area under the ROC curve.\n",
        "          - auprc: Area under the Precision-Recall curve.\n",
        "  \"\"\"\n",
        "  accuracy = accuracy_score(y_true, y_pred)\n",
        "  precision = precision_score(y_true, y_pred)\n",
        "  recall = recall_score(y_true, y_pred)\n",
        "  specificity = recall_score(y_true, y_pred, pos_label = 0)\n",
        "  f1 = f1_score(y_true, y_pred)\n",
        "  auroc = roc_auc_score(y_true, y_pred_proba)\n",
        "  auprc = average_precision_score(y_true, y_pred_proba)\n",
        "\n",
        "  metrics = {\n",
        "      f'{set}_accuracy': accuracy,\n",
        "      f'{set}_precision': precision,\n",
        "      f'{set}_recall': recall,\n",
        "      f'{set}_specificity': specificity,\n",
        "      f'{set}_f1': f1,\n",
        "      f'{set}_auroc': auroc,\n",
        "      f'{set}_auprc': auprc\n",
        "  }\n",
        "\n",
        "  return metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h7Z_2oDwYWIV"
      },
      "outputs": [],
      "source": [
        "def plot_roc_curve(y_true, y_pred_proba, path, set = 'Train'):\n",
        "    \"\"\"\n",
        "    Plots the ROC curve and computes the AUC.\n",
        "\n",
        "    Args:\n",
        "        y_true (array-like): True binary labels (0 or 1).\n",
        "        y_pred_proba (array-like): Predicted probabilities for the positive class.\n",
        "        title (str): Title of the plot.\n",
        "\n",
        "    Returns: None\n",
        "    \"\"\"\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_pred_proba)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure(figsize = (6, 5))\n",
        "    plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.4f}')\n",
        "    plt.plot([0, 1], [0, 1], linestyle = '--', color = 'gray')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'{set} ROC Curve')\n",
        "    plt.legend(loc = 'lower right')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(path)\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MmZHGrYcZQIE"
      },
      "outputs": [],
      "source": [
        "def plot_pr_curve(y_true, y_pred_proba, path, set = 'Train'):\n",
        "    \"\"\"\n",
        "    Plots the Precision-Recall curve and computes the average precision.\n",
        "\n",
        "    Args:\n",
        "        y_true (array-like): True binary labels (0 or 1).\n",
        "        y_pred_proba (array-like): Predicted probabilities for the positive class.\n",
        "        title (str): Title of the plot.\n",
        "\n",
        "    Returns: None\n",
        "    \"\"\"\n",
        "    precision, recall, _ = precision_recall_curve(y_true, y_pred_proba)\n",
        "    ap_score = average_precision_score(y_true, y_pred_proba)\n",
        "\n",
        "    plt.figure(figsize = (6, 5))\n",
        "    plt.plot(recall, precision, label = f'AUPRC = {ap_score:.4f}')\n",
        "    plt.xlabel('Recall')\n",
        "    plt.ylabel('Precision')\n",
        "    plt.title(f'{set} Recall-Precision Curve')\n",
        "    plt.legend(loc = 'lower left')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(path)\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cdR5qto3bBfP"
      },
      "outputs": [],
      "source": [
        "def create_confusion_matrix(y_true, y_pred, path, set = 'Train'):\n",
        "  \"\"\"\n",
        "  Generates and saves a confusion matrix plot for classification predictions.\n",
        "\n",
        "  Args:\n",
        "      y_true (array-like): Ground truth binary or multiclass labels.\n",
        "      y_pred (array-like): Predicted class labels.\n",
        "      path (str): File path to save the confusion matrix plot.\n",
        "      set (str, optional): Label for the dataset split (e.g., 'Train', 'Val', 'Test').\n",
        "                            Used in the plot title. Default is 'Train'.\n",
        "\n",
        "  Returns:\n",
        "      None. Saves the confusion matrix plot to the specified path.\n",
        "  \"\"\"\n",
        "  ConfusionMatrixDisplay.from_predictions(y_true, y_pred)\n",
        "  plt.title(f'{set} Confusion Matrix')\n",
        "  plt.savefig(path)\n",
        "  plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t_rssAP4oNba"
      },
      "outputs": [],
      "source": [
        "def create_objective(tfidf_suggestions, model_suggestions, model_name, X_train, y_train, X_val, y_val, experiment_id):\n",
        "  \"\"\"\n",
        "  Creates an Optuna objective function for hyperparameter optimization using a TF-IDF + ML model pipeline.\n",
        "\n",
        "  The returned objective function builds a pipeline with TF-IDF and a classifier, fits it on training data,\n",
        "  evaluates it on validation data, logs the run to MLflow, and returns the validation F1 score.\n",
        "\n",
        "  Args:\n",
        "      tfidf_suggestions (Dict[str, Callable[[optuna.Trial], Any]]):\n",
        "          Dictionary of hyperparameter suggestion functions for TF-IDF vectorizer.\n",
        "      model_suggestions (Dict[str, Callable[[optuna.Trial], Any]]):\n",
        "          Dictionary of hyperparameter suggestion functions for the classifier.\n",
        "      model_name (str):\n",
        "          Name of the model to use in the pipeline ('lr', 'xgb', 'lgbm', 'cat').\n",
        "      X_train (pd.Series or array-like):\n",
        "          Training feature data (text).\n",
        "      y_train (pd.Series or array-like):\n",
        "          Training labels.\n",
        "      X_val (pd.Series or array-like):\n",
        "          Validation feature data (text).\n",
        "      y_val (pd.Series or array-like):\n",
        "          Validation labels.\n",
        "      experiment_id (str):\n",
        "          MLflow experiment ID to log the nested runs under.\n",
        "\n",
        "  Returns:\n",
        "      Callable[[optuna.Trial], float]:\n",
        "          An objective function compatible with Optuna that returns validation F1 score.\n",
        "  \"\"\"\n",
        "  def objective(trial):\n",
        "    tfidf_params = {key: func(trial) for key, func in tfidf_suggestions.items()}\n",
        "    model_params = {key: func(trial) for key, func in model_suggestions.items()}\n",
        "\n",
        "    tfidf = TfidfVectorizer(**tfidf_params, lowercase = False, tokenizer = str.split)\n",
        "    model = create_model(model_name, model_params)\n",
        "\n",
        "    pipe = Pipeline([\n",
        "        ('tfidf', tfidf),\n",
        "        ('model', model)\n",
        "    ])\n",
        "\n",
        "    pipe.fit(X_train, y_train)\n",
        "\n",
        "    y_pred_proba = pipe.predict_proba(X_val)[:, 1]\n",
        "    y_pred = pipe.predict(X_val)\n",
        "\n",
        "    metrics = calculate_metrics(y_val, y_pred_proba, y_pred, set = 'val')\n",
        "\n",
        "    run_name = f'trial_{trial.number}'\n",
        "    with mlflow.start_run(run_name = run_name, experiment_id = experiment_id, nested = True) as run:\n",
        "      mlflow.log_param('tfidf_params', tfidf_params)\n",
        "      mlflow.log_param('model_params', model_params)\n",
        "      mlflow.log_metrics(metrics)\n",
        "      trial.set_user_attr('mlflow_run_id', run.info.run_id)\n",
        "\n",
        "    return metrics['val_f1']\n",
        "  return objective"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JdAqU72PdA9Y"
      },
      "outputs": [],
      "source": [
        "def log_mlflow(tfidf_suggestions, model_suggestions, model_name, X_train, y_train, X_val, y_val, X_test, y_test, n_trials, run_name, experiment_id):\n",
        "  \"\"\"\n",
        "  Runs hyperparameter tuning using Optuna, evaluates the best model, and logs all results to MLflow.\n",
        "\n",
        "  This function:\n",
        "    - Defines and optimizes an Optuna objective using a TF-IDF + classifier pipeline.\n",
        "    - Logs the best parameters and validation metrics.\n",
        "    - Re-trains the model on the full training set using the best parameters.\n",
        "    - Evaluates on train, validation, and test sets.\n",
        "    - Logs metrics, ROC & PR curves, confusion matrices, and the final model to MLflow.\n",
        "\n",
        "  Args:\n",
        "      tfidf_suggestions (Dict[str, Callable[[optuna.Trial], Any]]):\n",
        "          Dictionary of TF-IDF hyperparameter search spaces for Optuna.\n",
        "      model_suggestions (Dict[str, Callable[[optuna.Trial], Any]]):\n",
        "          Dictionary of model hyperparameter search spaces for Optuna.\n",
        "      model_name (str):\n",
        "          One of 'lr', 'xgb', 'lgbm', or 'cat' — specifies the classifier to use.\n",
        "      X_train, y_train:\n",
        "          Training data and labels.\n",
        "      X_val, y_val:\n",
        "          Validation data and labels.\n",
        "      X_test, y_test:\n",
        "          Test data and labels.\n",
        "      n_trials (int):\n",
        "          Number of Optuna trials to run.\n",
        "      run_name (str):\n",
        "          Name of the parent MLflow run.\n",
        "      experiment_id (str):\n",
        "          ID of the MLflow experiment where results should be logged.\n",
        "\n",
        "  Returns:\n",
        "      str: The MLflow run ID of the parent run.\n",
        "\n",
        "  Notes:\n",
        "      - Uses nested MLflow runs for each trial during tuning.\n",
        "      - Uses stratified performance metrics (AUROC, AUPRC, F1, etc.).\n",
        "      - Saves visualizations and logs them as MLflow artifacts.\n",
        "      - Logs the final trained model with input-output signature.\n",
        "  \"\"\"\n",
        "  objective = create_objective(tfidf_suggestions, model_suggestions, model_name, X_train, y_train, X_val, y_val, experiment_id)\n",
        "  direction = 'maximize'\n",
        "  study = optuna.create_study(direction = direction)\n",
        "\n",
        "  with mlflow.start_run(run_name = run_name, experiment_id = experiment_id) as run_outer:\n",
        "    study.optimize(objective, n_trials = n_trials)\n",
        "\n",
        "    mlflow.log_metric('best_optimize_metric', study.best_value)\n",
        "    mlflow.set_tag('best_trial_number', study.best_trial.number)\n",
        "\n",
        "    best_run_id = study.best_trial.user_attrs['mlflow_run_id']\n",
        "    run = mlflow.get_run(best_run_id)\n",
        "\n",
        "    best_tfidf_params = ast.literal_eval(run.data.params['tfidf_params'])\n",
        "    best_model_params = ast.literal_eval(run.data.params['model_params'])\n",
        "    mlflow.log_param('best_tfidf_params', best_tfidf_params)\n",
        "    mlflow.log_param('best_model_params', best_model_params)\n",
        "\n",
        "    tfidf = TfidfVectorizer(**best_tfidf_params, lowercase = False, tokenizer = str.split)\n",
        "    model = create_model(model_name, best_model_params)\n",
        "\n",
        "    pipe = Pipeline([\n",
        "        ('tfidf', tfidf),\n",
        "        ('model', model)\n",
        "    ])\n",
        "\n",
        "    pipe.fit(X_train, y_train)\n",
        "\n",
        "    train_pred_proba = pipe.predict_proba(X_train)[:, 1]\n",
        "    train_pred = pipe.predict(X_train)\n",
        "\n",
        "    train_metrics = calculate_metrics(y_train, train_pred_proba, train_pred, set = 'Train')\n",
        "    plot_roc_curve(y_train, train_pred_proba, path = f'./artifacts/{model_name}/train_roc_curve.png', set = 'Train')\n",
        "    plot_pr_curve(y_train, train_pred_proba, path = f'./artifacts/{model_name}/train_pr_curve.png', set = 'Train')\n",
        "    create_confusion_matrix(y_train, train_pred, path = f'./artifacts/{model_name}/train_confusion_matrix.png', set = 'Train')\n",
        "\n",
        "    mlflow.log_metrics(train_metrics)\n",
        "    mlflow.log_artifact(f'./artifacts/{model_name}/train_roc_curve.png')\n",
        "    mlflow.log_artifact(f'./artifacts/{model_name}/train_pr_curve.png')\n",
        "    mlflow.log_artifact(f'./artifacts/{model_name}/train_confusion_matrix.png')\n",
        "\n",
        "    val_pred_proba = pipe.predict_proba(X_val)[:, 1]\n",
        "    val_pred = pipe.predict(X_val)\n",
        "\n",
        "    val_metrics = calculate_metrics(y_val, val_pred_proba, val_pred, set = 'Val')\n",
        "    plot_roc_curve(y_val, val_pred_proba, path = f'./artifacts/{model_name}/val_roc_curve.png', set = 'Val')\n",
        "    plot_pr_curve(y_val, val_pred_proba, path = f'./artifacts/{model_name}/val_pr_curve.png', set = 'Val')\n",
        "    create_confusion_matrix(y_val, val_pred, path = f'./artifacts/{model_name}/val_confusion_matrix.png', set = 'Val')\n",
        "\n",
        "    mlflow.log_metrics(val_metrics)\n",
        "    mlflow.log_artifact(f'./artifacts/{model_name}/val_roc_curve.png')\n",
        "    mlflow.log_artifact(f'./artifacts/{model_name}/val_pr_curve.png')\n",
        "    mlflow.log_artifact(f'./artifacts/{model_name}/val_confusion_matrix.png')\n",
        "\n",
        "    test_pred_proba = pipe.predict_proba(X_test)[:, 1]\n",
        "    test_pred = pipe.predict(X_test)\n",
        "\n",
        "    test_metrics = calculate_metrics(y_test, test_pred_proba, test_pred, set = 'Test')\n",
        "    plot_roc_curve(y_test, test_pred_proba, path = f'./artifacts/{model_name}/test_roc_curve.png', set = 'Test')\n",
        "    plot_pr_curve(y_test, test_pred_proba, path = f'./artifacts/{model_name}/test_pr_curve.png', set = 'Test')\n",
        "    create_confusion_matrix(y_test, test_pred, path = f'./artifacts/{model_name}/test_confusion_matrix.png', set = 'Test')\n",
        "\n",
        "    mlflow.log_metrics(test_metrics)\n",
        "    mlflow.log_artifact(f'./artifacts/{model_name}/test_roc_curve.png')\n",
        "    mlflow.log_artifact(f'./artifacts/{model_name}/test_pr_curve.png')\n",
        "    mlflow.log_artifact(f'./artifacts/{model_name}/test_confusion_matrix.png')\n",
        "\n",
        "    signature = mlflow.models.infer_signature(X_train, y_train)\n",
        "    mlflow.sklearn.log_model(pipe, run_name, signature = signature)\n",
        "\n",
        "  return run_outer.info.run_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaSRN-DthDBF"
      },
      "source": [
        "## Setting Up MLFLow Tracking and Experiment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8lPvfC4bO6i"
      },
      "source": [
        "We configure MLflow to log all runs and artifacts to a custom directory (../experiments/) for better organization and portability. Then, we create or fetch an experiment named sentiment-analysis-amazon-reviews to group all related model runs.\n",
        "\n",
        "This setup allows us to:\n",
        "\n",
        "- Track hyperparameter tuning results\n",
        "\n",
        "- Compare model performance\n",
        "\n",
        "- Store artifacts like plots and trained models\n",
        "\n",
        "The retrieved experiment_id is used to link all runs to this specific experiment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vRPZpnJhgan",
        "outputId": "259cd4bd-8821-44ea-f7be-c09cfd1a4352"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Experiment ID: 617187074394259539\n"
          ]
        }
      ],
      "source": [
        "mlflow.set_tracking_uri('./experiments/')\n",
        "\n",
        "experiment_name = 'sentiment-analysis-amazon-reviews'\n",
        "mlflow.set_experiment(experiment_name)\n",
        "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
        "\n",
        "experiment_id = experiment.experiment_id\n",
        "print('Experiment ID:', experiment_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihAi9WZVokpC"
      },
      "source": [
        "## Defining TF-IDF Hyperparameter Search Space (Optuna)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8UvUFPIcWDu"
      },
      "source": [
        "We define a dictionary tfidf_suggestions that maps TF-IDF hyperparameters to Optuna search strategies. These settings allow the optimizer to explore different preprocessing configurations during hyperparameter tuning:\n",
        "\n",
        "- max_df: Upper bound on the document frequency for a term to be included (filters overly common words).\n",
        "\n",
        "- min_df: Lower bound on the document frequency (filters very rare words).\n",
        "\n",
        "- ngram_range: Decides whether to use unigrams, bigrams, or both.\n",
        "\n",
        "- max_features: Limits the number of tokens considered, helping control model complexity and speed.\n",
        "\n",
        "These values will be sampled dynamically by Optuna during each trial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8cSizX2OokCM"
      },
      "outputs": [],
      "source": [
        "tfidf_suggestions = {\n",
        "    'max_df': lambda trial: trial.suggest_float('max_df', 0.5, 1.0),\n",
        "    'min_df': lambda trial: trial.suggest_float('min_df', 0.01, 0.05),\n",
        "    'ngram_range': lambda trial: trial.suggest_categorical('ngram_range', [(1, 1), (1, 2), (2, 2)]),\n",
        "    'max_features': lambda trial: trial.suggest_int('max_features', 1000, 7000, step = 250)\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBNT9uvovUiI"
      },
      "source": [
        "## Defining Logistic Regression Hyperparameter Search Space and Launching Optuna + MLflow Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PimEp_ytc4wW"
      },
      "source": [
        "We define model_suggestions, a dictionary of hyperparameter options for Logistic Regression, which Optuna will explore to find the best performing model:\n",
        "\n",
        "- solver: Specifies the optimization algorithm; here, we use 'saga', which supports both L1 and L2 penalties.\n",
        "\n",
        "- penalty: Chooses between L1 and L2 regularization.\n",
        "\n",
        "- C: Inverse regularization strength (smaller = stronger regularization); explored on a log scale.\n",
        "\n",
        "- max_iter: Maximum number of iterations for convergence.\n",
        "\n",
        "- random_state: Random seed for reproducibility, varied across a range to increase robustness.\n",
        "\n",
        "We then call log_mlflow(...), which:\n",
        "\n",
        "- Runs Optuna for hyperparameter optimization over 25 trials.\n",
        "\n",
        "- Logs all runs, metrics, plots, and final models to MLflow.\n",
        "\n",
        "- Returns the MLflow run_id for future reference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMKGxeOaqa1t",
        "outputId": "8d441292-9006-4848-b217-1a5f9d25aed7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-04-24 02:53:01,172] A new study created in memory with name: no-name-f1cb429f-dc3b-4518-b40a-f71a00c6258d\n",
            "[I 2025-04-24 02:53:22,481] Trial 0 finished with value: 0.5834932821497121 and parameters: {'max_df': 0.9219462990764398, 'min_df': 0.021471461743854732, 'ngram_range': (1, 1), 'max_features': 3000, 'solver': 'saga', 'penalty': 'l1', 'C': 0.000609813504762927, 'max_iter': 300, 'random_state': 349}. Best is trial 0 with value: 0.5834932821497121.\n",
            "[I 2025-04-24 02:54:32,594] Trial 1 finished with value: 0.0 and parameters: {'max_df': 0.7423305443660055, 'min_df': 0.025424715477950586, 'ngram_range': (1, 2), 'max_features': 5250, 'solver': 'saga', 'penalty': 'l1', 'C': 0.00010645182072009795, 'max_iter': 300, 'random_state': 125}. Best is trial 0 with value: 0.5834932821497121.\n",
            "[I 2025-04-24 02:55:29,813] Trial 2 finished with value: 0.6710094756790903 and parameters: {'max_df': 0.9680012294032031, 'min_df': 0.016506066712895118, 'ngram_range': (2, 2), 'max_features': 6750, 'solver': 'saga', 'penalty': 'l1', 'C': 0.0010548028133377913, 'max_iter': 300, 'random_state': 235}. Best is trial 2 with value: 0.6710094756790903.\n",
            "[I 2025-04-24 02:56:27,901] Trial 3 finished with value: 0.6580982837973699 and parameters: {'max_df': 0.9172227793371952, 'min_df': 0.02070304191054481, 'ngram_range': (2, 2), 'max_features': 4500, 'solver': 'saga', 'penalty': 'l1', 'C': 0.001710929257419396, 'max_iter': 300, 'random_state': 251}. Best is trial 2 with value: 0.6710094756790903.\n",
            "[I 2025-04-24 02:56:47,479] Trial 4 finished with value: 0.6920446247171189 and parameters: {'max_df': 0.553606479873844, 'min_df': 0.048581003331667816, 'ngram_range': (1, 1), 'max_features': 2250, 'solver': 'saga', 'penalty': 'l2', 'C': 189.54968525461248, 'max_iter': 300, 'random_state': 104}. Best is trial 4 with value: 0.6920446247171189.\n",
            "[I 2025-04-24 02:58:03,730] Trial 5 finished with value: 0.7975064025768129 and parameters: {'max_df': 0.8646533496561335, 'min_df': 0.012891143562682443, 'ngram_range': (1, 2), 'max_features': 5500, 'solver': 'saga', 'penalty': 'l2', 'C': 0.36529682865119467, 'max_iter': 300, 'random_state': 233}. Best is trial 5 with value: 0.7975064025768129.\n",
            "[I 2025-04-24 02:58:24,233] Trial 6 finished with value: 0.7785399490763782 and parameters: {'max_df': 0.6918053714260785, 'min_df': 0.018378609799899727, 'ngram_range': (1, 1), 'max_features': 2250, 'solver': 'saga', 'penalty': 'l2', 'C': 0.01347838622915726, 'max_iter': 300, 'random_state': 147}. Best is trial 5 with value: 0.7975064025768129.\n",
            "[I 2025-04-24 02:59:21,903] Trial 7 finished with value: 0.6578959338909808 and parameters: {'max_df': 0.8794805021665073, 'min_df': 0.023235745241644123, 'ngram_range': (2, 2), 'max_features': 6750, 'solver': 'saga', 'penalty': 'l1', 'C': 5.8249784186158715, 'max_iter': 300, 'random_state': 272}. Best is trial 5 with value: 0.7975064025768129.\n",
            "[I 2025-04-24 03:00:39,028] Trial 8 finished with value: 0.6561439978084488 and parameters: {'max_df': 0.625486799559648, 'min_df': 0.028449738484174647, 'ngram_range': (1, 2), 'max_features': 2250, 'solver': 'saga', 'penalty': 'l1', 'C': 0.0008244366435022684, 'max_iter': 300, 'random_state': 322}. Best is trial 5 with value: 0.7975064025768129.\n",
            "[I 2025-04-24 03:00:59,397] Trial 9 finished with value: 0.7586472895577565 and parameters: {'max_df': 0.7825109044414964, 'min_df': 0.017698183084440808, 'ngram_range': (1, 1), 'max_features': 6500, 'solver': 'saga', 'penalty': 'l2', 'C': 0.00045303828144568567, 'max_iter': 300, 'random_state': 153}. Best is trial 5 with value: 0.7975064025768129.\n",
            "[I 2025-04-24 03:02:16,397] Trial 10 finished with value: 0.7161724001581653 and parameters: {'max_df': 0.824874103369738, 'min_df': 0.03712476487932964, 'ngram_range': (1, 2), 'max_features': 5250, 'solver': 'saga', 'penalty': 'l2', 'C': 0.6781110971577327, 'max_iter': 300, 'random_state': 400}. Best is trial 5 with value: 0.7975064025768129.\n",
            "[I 2025-04-24 03:02:38,662] Trial 11 finished with value: 0.8067825713672462 and parameters: {'max_df': 0.690073013508401, 'min_df': 0.010159735283704861, 'ngram_range': (1, 1), 'max_features': 1000, 'solver': 'saga', 'penalty': 'l2', 'C': 0.043054737283891635, 'max_iter': 300, 'random_state': 187}. Best is trial 11 with value: 0.8067825713672462.\n",
            "[I 2025-04-24 03:03:55,650] Trial 12 finished with value: 0.8025487750684499 and parameters: {'max_df': 0.6705237171942184, 'min_df': 0.011382967560617643, 'ngram_range': (1, 2), 'max_features': 1000, 'solver': 'saga', 'penalty': 'l2', 'C': 0.08086794197723324, 'max_iter': 300, 'random_state': 198}. Best is trial 11 with value: 0.8067825713672462.\n",
            "[I 2025-04-24 03:04:17,348] Trial 13 finished with value: 0.7956956784266368 and parameters: {'max_df': 0.6430285067784749, 'min_df': 0.0124273018205311, 'ngram_range': (1, 1), 'max_features': 1250, 'solver': 'saga', 'penalty': 'l2', 'C': 0.0219599847875598, 'max_iter': 300, 'random_state': 190}. Best is trial 11 with value: 0.8067825713672462.\n",
            "[I 2025-04-24 03:05:33,582] Trial 14 finished with value: 0.7200184136894272 and parameters: {'max_df': 0.5015257035762619, 'min_df': 0.035437812452833534, 'ngram_range': (1, 2), 'max_features': 1000, 'solver': 'saga', 'penalty': 'l2', 'C': 0.028746260250003857, 'max_iter': 300, 'random_state': 190}. Best is trial 11 with value: 0.8067825713672462.\n",
            "[I 2025-04-24 03:06:51,425] Trial 15 finished with value: 0.8046131516291175 and parameters: {'max_df': 0.7029219602727758, 'min_df': 0.011008427625885022, 'ngram_range': (1, 2), 'max_features': 3750, 'solver': 'saga', 'penalty': 'l2', 'C': 6.641971987820372, 'max_iter': 300, 'random_state': 193}. Best is trial 11 with value: 0.8067825713672462.\n",
            "[I 2025-04-24 03:07:14,386] Trial 16 finished with value: 0.8050808710064582 and parameters: {'max_df': 0.7378270133112199, 'min_df': 0.010537978031094958, 'ngram_range': (1, 1), 'max_features': 3500, 'solver': 'saga', 'penalty': 'l2', 'C': 27.91360355943954, 'max_iter': 300, 'random_state': 293}. Best is trial 11 with value: 0.8067825713672462.\n",
            "[I 2025-04-24 03:07:35,069] Trial 17 finished with value: 0.6987610773619004 and parameters: {'max_df': 0.5964725736955281, 'min_df': 0.04684048297866451, 'ngram_range': (1, 1), 'max_features': 3750, 'solver': 'saga', 'penalty': 'l2', 'C': 459.9369039653654, 'max_iter': 300, 'random_state': 293}. Best is trial 11 with value: 0.8067825713672462.\n",
            "[I 2025-04-24 03:07:55,346] Trial 18 finished with value: 0.7221809134326651 and parameters: {'max_df': 0.760672084312036, 'min_df': 0.03603237877502083, 'ngram_range': (1, 1), 'max_features': 3250, 'solver': 'saga', 'penalty': 'l2', 'C': 34.74970916892566, 'max_iter': 300, 'random_state': 319}. Best is trial 11 with value: 0.8067825713672462.\n",
            "[I 2025-04-24 03:08:15,384] Trial 19 finished with value: 0.7306316184320628 and parameters: {'max_df': 0.8075662275611902, 'min_df': 0.03111444045847154, 'ngram_range': (1, 1), 'max_features': 1750, 'solver': 'saga', 'penalty': 'l2', 'C': 1.6727372342078126, 'max_iter': 300, 'random_state': 362}. Best is trial 11 with value: 0.8067825713672462.\n",
            "[I 2025-04-24 03:08:37,350] Trial 20 finished with value: 0.7869174701561065 and parameters: {'max_df': 0.7255676484091889, 'min_df': 0.015429486780409821, 'ngram_range': (1, 1), 'max_features': 4500, 'solver': 'saga', 'penalty': 'l2', 'C': 42.03830302603473, 'max_iter': 300, 'random_state': 280}. Best is trial 11 with value: 0.8067825713672462.\n",
            "[I 2025-04-24 03:08:58,699] Trial 21 finished with value: 0.8026644939033978 and parameters: {'max_df': 0.6931637686176014, 'min_df': 0.011623562191473157, 'ngram_range': (1, 1), 'max_features': 3250, 'solver': 'saga', 'penalty': 'l2', 'C': 7.391809997097916, 'max_iter': 300, 'random_state': 206}. Best is trial 11 with value: 0.8067825713672462.\n",
            "[I 2025-04-24 03:10:17,554] Trial 22 finished with value: 0.806816071760152 and parameters: {'max_df': 0.7103027636244047, 'min_df': 0.010222523356200563, 'ngram_range': (1, 2), 'max_features': 4000, 'solver': 'saga', 'penalty': 'l2', 'C': 4.207606545268174, 'max_iter': 300, 'random_state': 157}. Best is trial 22 with value: 0.806816071760152.\n",
            "[I 2025-04-24 03:11:15,142] Trial 23 finished with value: 0.6625776536136828 and parameters: {'max_df': 0.604572502307473, 'min_df': 0.015492474679166684, 'ngram_range': (2, 2), 'max_features': 4500, 'solver': 'saga', 'penalty': 'l2', 'C': 46.660588307284875, 'max_iter': 300, 'random_state': 161}. Best is trial 22 with value: 0.806816071760152.\n",
            "[I 2025-04-24 03:11:36,086] Trial 24 finished with value: 0.7899743188763433 and parameters: {'max_df': 0.6538572922070947, 'min_df': 0.014577476820289807, 'ngram_range': (1, 1), 'max_features': 2750, 'solver': 'saga', 'penalty': 'l2', 'C': 0.1326413739049261, 'max_iter': 300, 'random_state': 167}. Best is trial 22 with value: 0.806816071760152.\n"
          ]
        }
      ],
      "source": [
        "model_suggestions = {\n",
        "    'solver': lambda trial: trial.suggest_categorical('solver', ['saga']),\n",
        "    'penalty': lambda trial: trial.suggest_categorical('penalty', ['l1', 'l2']),\n",
        "    'C': lambda trial: trial.suggest_float('C', 1e-4, 1e3, log = True),\n",
        "    'max_iter': lambda trial: trial.suggest_int('max_iter', 300, 300, step = 1),\n",
        "    'random_state': lambda trial: trial.suggest_int('random_state', 100, 400, step = 1)\n",
        "}\n",
        "\n",
        "run_id = log_mlflow(tfidf_suggestions, model_suggestions, 'lr', X_train, y_train, X_val, y_val, X_test, y_test, 25, 'lr', experiment_id = experiment_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttBPeb1bHUQI"
      },
      "source": [
        "## Defining XGBoost Hyperparameter Search Space and Launching Optuna + MLflow Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wtCafYDdiu7"
      },
      "source": [
        "In this section, we define a set of hyperparameters for XGBoost that Optuna will optimize to maximize model performance. The parameters explored include:\n",
        "\n",
        "- max_depth: Maximum depth of each tree; controls model complexity.\n",
        "\n",
        "- learning_rate: Step size shrinkage to prevent overfitting; sampled on a log scale.\n",
        "\n",
        "- subsample: Fraction of samples used for training each tree to introduce stochasticity.\n",
        "\n",
        "- alpha & lambda: L1 and L2 regularization terms, respectively.\n",
        "\n",
        "- gamma: Minimum loss reduction to make a further partition; helps with pruning.\n",
        "\n",
        "- n_estimators: Number of boosting rounds (trees).\n",
        "\n",
        "- random_state: Seed for reproducibility.\n",
        "\n",
        "We then pass this configuration to log_mlflow(...), which:\n",
        "\n",
        "- Tunes the hyperparameters over 2 trials using Optuna (limited here for demo purposes).\n",
        "\n",
        "- Logs parameters, metrics, plots, and models to MLflow.\n",
        "\n",
        "- Returns the run_id of the parent MLflow run for traceability."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73Vz3arcvlfw",
        "outputId": "f7c05034-2feb-4942-9218-76fd48daf673"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-04-24 03:14:16,317] A new study created in memory with name: no-name-c589146c-1a73-4524-be84-9da3756fe039\n",
            "[I 2025-04-24 03:14:36,285] Trial 0 finished with value: 0.5704261704156715 and parameters: {'max_df': 0.6822703653483534, 'min_df': 0.03907488044770374, 'ngram_range': (1, 1), 'max_features': 2500, 'max_depth': 5, 'learning_rate': 0.0010807817127471916, 'subsample': 0.9082890809540323, 'alpha': 3.3264834166103885, 'lambda': 7.434273417768309, 'gamma': 9.683322075212534, 'n_estimators': 188, 'random_state': 358}. Best is trial 0 with value: 0.5704261704156715.\n",
            "[I 2025-04-24 03:16:12,213] Trial 1 finished with value: 0.5938117978255801 and parameters: {'max_df': 0.7949532042967156, 'min_df': 0.02284011131188271, 'ngram_range': (1, 2), 'max_features': 7000, 'max_depth': 6, 'learning_rate': 0.00017874965991000134, 'subsample': 0.9697870464582811, 'alpha': 9.813420861221827, 'lambda': 8.930185799385065, 'gamma': 2.9025372676540817, 'n_estimators': 439, 'random_state': 241}. Best is trial 1 with value: 0.5938117978255801.\n",
            "[I 2025-04-24 03:16:32,070] Trial 2 finished with value: 0.5447690857681433 and parameters: {'max_df': 0.6381672630941049, 'min_df': 0.02701850436151737, 'ngram_range': (1, 1), 'max_features': 4750, 'max_depth': 4, 'learning_rate': 1.9111331263565495e-05, 'subsample': 0.5465035072591112, 'alpha': 7.680225120764717, 'lambda': 2.1710112537243766, 'gamma': 8.326594430598936, 'n_estimators': 247, 'random_state': 284}. Best is trial 1 with value: 0.5938117978255801.\n",
            "[I 2025-04-24 03:17:04,474] Trial 3 finished with value: 0.5356885166546411 and parameters: {'max_df': 0.8904023688992667, 'min_df': 0.01441555445973743, 'ngram_range': (1, 1), 'max_features': 6500, 'max_depth': 4, 'learning_rate': 2.7866593070294162e-05, 'subsample': 0.6146877942179401, 'alpha': 1.6226562286514878, 'lambda': 3.531401528290541, 'gamma': 7.629973666355437, 'n_estimators': 474, 'random_state': 332}. Best is trial 1 with value: 0.5938117978255801.\n",
            "[I 2025-04-24 03:18:01,700] Trial 4 finished with value: 0.6568840778158967 and parameters: {'max_df': 0.5255314748493727, 'min_df': 0.02621013702990043, 'ngram_range': (2, 2), 'max_features': 6500, 'max_depth': 4, 'learning_rate': 0.038495846206794686, 'subsample': 0.6071091875157277, 'alpha': 8.919069335185203, 'lambda': 7.375324580427244, 'gamma': 8.815693247244141, 'n_estimators': 298, 'random_state': 205}. Best is trial 4 with value: 0.6568840778158967.\n",
            "[I 2025-04-24 03:19:23,105] Trial 5 finished with value: 0.6813906617400067 and parameters: {'max_df': 0.9419632699627587, 'min_df': 0.044144061731119975, 'ngram_range': (1, 2), 'max_features': 1750, 'max_depth': 5, 'learning_rate': 0.01573930605971217, 'subsample': 0.9881642566570843, 'alpha': 6.589197686693735, 'lambda': 1.229740115402559, 'gamma': 2.449203988064691, 'n_estimators': 409, 'random_state': 243}. Best is trial 5 with value: 0.6813906617400067.\n",
            "[I 2025-04-24 03:20:20,940] Trial 6 finished with value: 0.0953493806964244 and parameters: {'max_df': 0.9555135942415804, 'min_df': 0.044969404418210686, 'ngram_range': (2, 2), 'max_features': 4000, 'max_depth': 4, 'learning_rate': 0.01210229207406567, 'subsample': 0.5784309616608079, 'alpha': 1.6852258328230152, 'lambda': 2.6156815141746623, 'gamma': 4.233074062765036, 'n_estimators': 476, 'random_state': 221}. Best is trial 5 with value: 0.6813906617400067.\n",
            "[I 2025-04-24 03:23:26,871] Trial 7 finished with value: 0.7278892513567314 and parameters: {'max_df': 0.6260080054257785, 'min_df': 0.023796844203908714, 'ngram_range': (1, 2), 'max_features': 4000, 'max_depth': 12, 'learning_rate': 0.009414551162417198, 'subsample': 0.862014263662206, 'alpha': 0.7397306048123231, 'lambda': 2.7093198919753467, 'gamma': 1.7650708723930186, 'n_estimators': 317, 'random_state': 356}. Best is trial 7 with value: 0.7278892513567314.\n",
            "[I 2025-04-24 03:24:53,046] Trial 8 finished with value: 0.6692155837670394 and parameters: {'max_df': 0.7936609273902131, 'min_df': 0.03942310316815802, 'ngram_range': (1, 2), 'max_features': 2750, 'max_depth': 5, 'learning_rate': 0.009124875644262162, 'subsample': 0.7859932629457937, 'alpha': 2.6128165471569273, 'lambda': 0.3361747687253247, 'gamma': 5.721786965911663, 'n_estimators': 500, 'random_state': 297}. Best is trial 7 with value: 0.7278892513567314.\n",
            "[I 2025-04-24 03:26:35,723] Trial 9 finished with value: 0.7225506078783368 and parameters: {'max_df': 0.616608153551908, 'min_df': 0.03956984747595823, 'ngram_range': (1, 2), 'max_features': 2250, 'max_depth': 12, 'learning_rate': 0.04818387645806449, 'subsample': 0.8056449725042321, 'alpha': 3.3482709562807447, 'lambda': 3.877191014347281, 'gamma': 7.610022102740932, 'n_estimators': 346, 'random_state': 288}. Best is trial 7 with value: 0.7278892513567314.\n",
            "[I 2025-04-24 03:29:08,129] Trial 10 finished with value: 0.6541261429153806 and parameters: {'max_df': 0.5137427895534236, 'min_df': 0.011020923572071952, 'ngram_range': (1, 2), 'max_features': 5000, 'max_depth': 12, 'learning_rate': 0.0016304335307137307, 'subsample': 0.7012489340583632, 'alpha': 0.14625987641002336, 'lambda': 5.16120518245426, 'gamma': 0.3929223290351018, 'n_estimators': 136, 'random_state': 123}. Best is trial 7 with value: 0.7278892513567314.\n",
            "[I 2025-04-24 03:30:45,687] Trial 11 finished with value: 0.7417769159767886 and parameters: {'max_df': 0.6138474388597788, 'min_df': 0.034024740914408685, 'ngram_range': (1, 2), 'max_features': 1000, 'max_depth': 12, 'learning_rate': 0.08624872302400993, 'subsample': 0.8343849706522618, 'alpha': 4.115823430150219, 'lambda': 4.6301816981270205, 'gamma': 6.467909861028784, 'n_estimators': 360, 'random_state': 400}. Best is trial 11 with value: 0.7417769159767886.\n",
            "[I 2025-04-24 03:32:22,840] Trial 12 finished with value: 0.7433425958087299 and parameters: {'max_df': 0.5916906651877287, 'min_df': 0.03263448190400586, 'ngram_range': (1, 2), 'max_features': 1000, 'max_depth': 10, 'learning_rate': 0.0862946458940795, 'subsample': 0.8601847227765804, 'alpha': 5.169319564310409, 'lambda': 5.477671416836646, 'gamma': 5.643917411708309, 'n_estimators': 367, 'random_state': 392}. Best is trial 12 with value: 0.7433425958087299.\n",
            "[I 2025-04-24 03:33:56,828] Trial 13 finished with value: 0.7438391277663453 and parameters: {'max_df': 0.7350407120516328, 'min_df': 0.03336256476653776, 'ngram_range': (1, 2), 'max_features': 1000, 'max_depth': 10, 'learning_rate': 0.09568304097050526, 'subsample': 0.6989155353976546, 'alpha': 4.985323589029299, 'lambda': 5.366949845137499, 'gamma': 5.688529197943476, 'n_estimators': 376, 'random_state': 394}. Best is trial 13 with value: 0.7438391277663453.\n",
            "[I 2025-04-24 03:35:48,212] Trial 14 finished with value: 0.6581332992849847 and parameters: {'max_df': 0.7232835160743598, 'min_df': 0.03169205747024916, 'ngram_range': (1, 2), 'max_features': 1250, 'max_depth': 9, 'learning_rate': 0.0030013027240853372, 'subsample': 0.6990122477050197, 'alpha': 5.736954513617021, 'lambda': 5.9212193212745206, 'gamma': 4.240793726749532, 'n_estimators': 395, 'random_state': 400}. Best is trial 13 with value: 0.7438391277663453.\n",
            "[I 2025-04-24 03:36:47,036] Trial 15 finished with value: 0.6609538039365043 and parameters: {'max_df': 0.8568435604134597, 'min_df': 0.035112229997672, 'ngram_range': (2, 2), 'max_features': 3000, 'max_depth': 9, 'learning_rate': 0.00018338787052777869, 'subsample': 0.7367828831351477, 'alpha': 5.111751233315272, 'lambda': 6.501413923653915, 'gamma': 6.071728278101387, 'n_estimators': 285, 'random_state': 178}. Best is trial 13 with value: 0.7438391277663453.\n",
            "[I 2025-04-24 03:38:25,727] Trial 16 finished with value: 0.7849805222911557 and parameters: {'max_df': 0.560889292929723, 'min_df': 0.020330964398337696, 'ngram_range': (1, 2), 'max_features': 1750, 'max_depth': 10, 'learning_rate': 0.0979781400574, 'subsample': 0.6616621298773522, 'alpha': 6.630864640799373, 'lambda': 9.994422144694209, 'gamma': 4.485617259156932, 'n_estimators': 217, 'random_state': 337}. Best is trial 16 with value: 0.7849805222911557.\n",
            "[I 2025-04-24 03:40:19,736] Trial 17 finished with value: 0.625482033863677 and parameters: {'max_df': 0.7391407964864137, 'min_df': 0.019501611422297456, 'ngram_range': (1, 2), 'max_features': 1750, 'max_depth': 10, 'learning_rate': 0.0001943712691163503, 'subsample': 0.6671687948337728, 'alpha': 7.079847128057531, 'lambda': 9.661143821071416, 'gamma': 3.9933102938246297, 'n_estimators': 218, 'random_state': 337}. Best is trial 16 with value: 0.7849805222911557.\n",
            "[I 2025-04-24 03:41:18,018] Trial 18 finished with value: 0.6588965954012891 and parameters: {'max_df': 0.5614149809716813, 'min_df': 0.018458768423971112, 'ngram_range': (2, 2), 'max_features': 3250, 'max_depth': 8, 'learning_rate': 0.003978346185019894, 'subsample': 0.5153435118109354, 'alpha': 8.26891662394074, 'lambda': 8.076876827150437, 'gamma': 4.642687649538323, 'n_estimators': 101, 'random_state': 307}. Best is trial 16 with value: 0.7849805222911557.\n",
            "[I 2025-04-24 03:41:48,520] Trial 19 finished with value: 0.6881561569628187 and parameters: {'max_df': 0.8057320603641013, 'min_df': 0.04833086380104934, 'ngram_range': (1, 1), 'max_features': 1750, 'max_depth': 10, 'learning_rate': 0.02619207008531705, 'subsample': 0.6593594902344269, 'alpha': 6.181279187310438, 'lambda': 9.798427615629727, 'gamma': 3.2751376151539464, 'n_estimators': 176, 'random_state': 373}. Best is trial 16 with value: 0.7849805222911557.\n",
            "[I 2025-04-24 03:43:25,048] Trial 20 finished with value: 0.6145765943682113 and parameters: {'max_df': 0.6778643621866867, 'min_df': 0.017943292929278775, 'ngram_range': (1, 2), 'max_features': 3500, 'max_depth': 7, 'learning_rate': 0.00044368557469375887, 'subsample': 0.7615319007761981, 'alpha': 4.14230711790608, 'lambda': 8.821037377317564, 'gamma': 6.916740152181787, 'n_estimators': 260, 'random_state': 329}. Best is trial 16 with value: 0.7849805222911557.\n",
            "[I 2025-04-24 03:45:09,436] Trial 21 finished with value: 0.7498646023642233 and parameters: {'max_df': 0.5818890423884291, 'min_df': 0.030398229866390306, 'ngram_range': (1, 2), 'max_features': 1000, 'max_depth': 10, 'learning_rate': 0.06923504677527041, 'subsample': 0.883461316097312, 'alpha': 5.184743650638523, 'lambda': 5.935213311079664, 'gamma': 5.327535388675265, 'n_estimators': 396, 'random_state': 381}. Best is trial 16 with value: 0.7849805222911557.\n",
            "[I 2025-04-24 03:46:55,656] Trial 22 finished with value: 0.7574303360686635 and parameters: {'max_df': 0.5741573397849699, 'min_df': 0.028630372533454664, 'ngram_range': (1, 2), 'max_features': 1500, 'max_depth': 11, 'learning_rate': 0.09154581075010591, 'subsample': 0.9081260051217632, 'alpha': 4.709308596064414, 'lambda': 6.576909454865282, 'gamma': 5.208678104293127, 'n_estimators': 422, 'random_state': 374}. Best is trial 16 with value: 0.7849805222911557.\n",
            "[I 2025-04-24 03:49:05,184] Trial 23 finished with value: 0.7472294821066157 and parameters: {'max_df': 0.5596002634187774, 'min_df': 0.02908835729958545, 'ngram_range': (1, 2), 'max_features': 2000, 'max_depth': 11, 'learning_rate': 0.026343823191521492, 'subsample': 0.9271714603737559, 'alpha': 7.106288512509237, 'lambda': 6.605617152380319, 'gamma': 5.1469263699969865, 'n_estimators': 434, 'random_state': 367}. Best is trial 16 with value: 0.7849805222911557.\n",
            "[I 2025-04-24 03:51:19,248] Trial 24 finished with value: 0.7733095981556599 and parameters: {'max_df': 0.5542606046987597, 'min_df': 0.021620858501919676, 'ngram_range': (1, 2), 'max_features': 1500, 'max_depth': 11, 'learning_rate': 0.04720192083203357, 'subsample': 0.9217947590209686, 'alpha': 5.9557933820602695, 'lambda': 7.4969214651608995, 'gamma': 3.560828826046847, 'n_estimators': 327, 'random_state': 311}. Best is trial 16 with value: 0.7849805222911557.\n"
          ]
        }
      ],
      "source": [
        "model_suggestions = {\n",
        "    'max_depth': lambda trial: trial.suggest_int('max_depth', 3, 12, step = 1),\n",
        "    'learning_rate': lambda trial: trial.suggest_float('learning_rate', 1e-5, 0.1, log = True),\n",
        "    'subsample': lambda trial: trial.suggest_float('subsample', 0.5, 1),\n",
        "    'alpha': lambda trial: trial.suggest_float('alpha', 0, 10),\n",
        "    'lambda': lambda trial: trial.suggest_float('lambda', 0, 10),\n",
        "    'gamma': lambda trial: trial.suggest_float('gamma', 0, 10),\n",
        "    'n_estimators': lambda trial: trial.suggest_int('n_estimators', 100, 500, step = 1),\n",
        "    'random_state': lambda trial: trial.suggest_int('random_state', 100, 400, step = 1)\n",
        "}\n",
        "\n",
        "run_id = log_mlflow(tfidf_suggestions, model_suggestions, 'xgb', X_train, y_train, X_val, y_val, X_test, y_test, 25, 'xgboost', experiment_id = experiment_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnsGemRllMgd"
      },
      "source": [
        "## Defining LightGBM Hyperparameter Search Space and Launching Optuna + MLflow Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPJ9M9UIiM-8"
      },
      "source": [
        "In this section, we define a hyperparameter search space for LightGBM using Optuna. This configuration includes regularization, sampling, and tree-building parameters:\n",
        "\n",
        "- max_depth: Maximum depth of trees.\n",
        "\n",
        "- learning_rate: Controls how much each tree contributes to the final prediction; lower values slow learning.\n",
        "\n",
        "- feature_fraction: Fraction of features randomly selected in each boosting round (column sampling).\n",
        "\n",
        "- bagging_fraction: Fraction of data randomly selected for each iteration (row sampling).\n",
        "\n",
        "- lambda_l1 & lambda_l2: L1 and L2 regularization terms.\n",
        "\n",
        "- boosting_type: The boosting method used (here we constrain to 'gbdt').\n",
        "\n",
        "- n_estimators: Number of trees in the model.\n",
        "\n",
        "- random_state: Seed to ensure reproducibility.\n",
        "\n",
        "- verbose: Controls output verbosity during training.\n",
        "\n",
        "We run log_mlflow(...) to:\n",
        "\n",
        "- Optimize LightGBM hyperparameters over 25 Optuna trials.\n",
        "\n",
        "- Log the best parameters, performance metrics, confusion matrices, and PR/ROC curves to MLflow.\n",
        "\n",
        "- Save the trained model and evaluation artifacts to a tracked experiment for easy comparison."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILIlnyaLvpN4",
        "outputId": "aed6a28f-3fc8-46fc-ea3b-f15b5ac09190"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-04-24 03:54:22,041] A new study created in memory with name: no-name-5d36e649-c416-4d4b-9b69-f61bb01f74b7\n",
            "[I 2025-04-24 03:55:36,212] Trial 0 finished with value: 0.6015875388166525 and parameters: {'max_df': 0.5380768028772736, 'min_df': 0.04507304985198902, 'ngram_range': (1, 2), 'max_features': 3250, 'max_depth': 7, 'learning_rate': 3.472102811598749e-05, 'feature_fraction': 0.9368303649762355, 'bagging_fraction': 0.9297613781472126, 'lambda_l1': 0.4611955075296881, 'boosting_type': 'gbdt', 'n_estimators': 116, 'random_state': 174, 'verbose': -1}. Best is trial 0 with value: 0.6015875388166525.\n",
            "[I 2025-04-24 03:56:34,260] Trial 1 finished with value: 0.6609538039365043 and parameters: {'max_df': 0.983253153030452, 'min_df': 0.0395784357721554, 'ngram_range': (2, 2), 'max_features': 3250, 'max_depth': 11, 'learning_rate': 0.045606450082927484, 'feature_fraction': 0.8651691330974973, 'bagging_fraction': 0.5666090697832743, 'lambda_l1': 26.326945753771458, 'boosting_type': 'gbdt', 'n_estimators': 260, 'random_state': 395, 'verbose': -1}. Best is trial 1 with value: 0.6609538039365043.\n",
            "[I 2025-04-24 03:57:33,417] Trial 2 finished with value: 0.6570012243557202 and parameters: {'max_df': 0.7811276062349513, 'min_df': 0.023598413156400825, 'ngram_range': (2, 2), 'max_features': 2500, 'max_depth': 5, 'learning_rate': 0.0010960391948731858, 'feature_fraction': 0.5031626858259346, 'bagging_fraction': 0.5252714617203369, 'lambda_l1': 81.71462541258973, 'boosting_type': 'gbdt', 'n_estimators': 479, 'random_state': 115, 'verbose': -1}. Best is trial 1 with value: 0.6609538039365043.\n",
            "[I 2025-04-24 03:57:51,312] Trial 3 finished with value: 0.5957096852384085 and parameters: {'max_df': 0.8324295904003817, 'min_df': 0.0318743126417781, 'ngram_range': (1, 1), 'max_features': 6750, 'max_depth': 5, 'learning_rate': 8.714018921464685e-05, 'feature_fraction': 0.5533678892542361, 'bagging_fraction': 0.7660226122750287, 'lambda_l1': 43.976922838523194, 'boosting_type': 'gbdt', 'n_estimators': 129, 'random_state': 179, 'verbose': -1}. Best is trial 1 with value: 0.6609538039365043.\n",
            "[I 2025-04-24 03:58:49,843] Trial 4 finished with value: 0.6642022469498782 and parameters: {'max_df': 0.7983515182111518, 'min_df': 0.011703041325198544, 'ngram_range': (2, 2), 'max_features': 6000, 'max_depth': 11, 'learning_rate': 0.06639155870636368, 'feature_fraction': 0.7226606360172761, 'bagging_fraction': 0.7886088528711279, 'lambda_l1': 76.33179590469831, 'boosting_type': 'gbdt', 'n_estimators': 230, 'random_state': 337, 'verbose': -1}. Best is trial 4 with value: 0.6642022469498782.\n",
            "[I 2025-04-24 03:59:10,009] Trial 5 finished with value: 0.6267504593775958 and parameters: {'max_df': 0.7186236889215118, 'min_df': 0.026914168104870323, 'ngram_range': (1, 1), 'max_features': 5250, 'max_depth': 10, 'learning_rate': 0.0010008054945980435, 'feature_fraction': 0.8151622646587869, 'bagging_fraction': 0.8305678094792914, 'lambda_l1': 57.03933268721644, 'boosting_type': 'gbdt', 'n_estimators': 215, 'random_state': 144, 'verbose': -1}. Best is trial 4 with value: 0.6642022469498782.\n",
            "[I 2025-04-24 03:59:27,381] Trial 6 finished with value: 0.62230995760655 and parameters: {'max_df': 0.5677569858496612, 'min_df': 0.049587490883417275, 'ngram_range': (1, 1), 'max_features': 1500, 'max_depth': 9, 'learning_rate': 0.0034216774858552186, 'feature_fraction': 0.80388967130373, 'bagging_fraction': 0.6451433395359705, 'lambda_l1': 57.58154568313074, 'boosting_type': 'gbdt', 'n_estimators': 169, 'random_state': 400, 'verbose': -1}. Best is trial 4 with value: 0.6642022469498782.\n",
            "[I 2025-04-24 03:59:43,150] Trial 7 finished with value: 0.6362691010121055 and parameters: {'max_df': 0.853868589462019, 'min_df': 0.045168047969839434, 'ngram_range': (1, 1), 'max_features': 4250, 'max_depth': 10, 'learning_rate': 4.788657753029323e-05, 'feature_fraction': 0.8248157133290983, 'bagging_fraction': 0.5319227609319257, 'lambda_l1': 34.446101068375256, 'boosting_type': 'gbdt', 'n_estimators': 110, 'random_state': 265, 'verbose': -1}. Best is trial 4 with value: 0.6642022469498782.\n",
            "[I 2025-04-24 04:01:05,345] Trial 8 finished with value: 0.599369518721171 and parameters: {'max_df': 0.5143713341201037, 'min_df': 0.033693424189434495, 'ngram_range': (1, 2), 'max_features': 1000, 'max_depth': 6, 'learning_rate': 0.0023155098560553727, 'feature_fraction': 0.9536411957182116, 'bagging_fraction': 0.9567498036360631, 'lambda_l1': 87.75149411633409, 'boosting_type': 'gbdt', 'n_estimators': 471, 'random_state': 188, 'verbose': -1}. Best is trial 4 with value: 0.6642022469498782.\n",
            "[I 2025-04-24 04:02:20,310] Trial 9 finished with value: 0.6137951686963465 and parameters: {'max_df': 0.9318348115255402, 'min_df': 0.04643829412729253, 'ngram_range': (1, 2), 'max_features': 1750, 'max_depth': 7, 'learning_rate': 0.00017369008078133496, 'feature_fraction': 0.6783617961125095, 'bagging_fraction': 0.5282550014032323, 'lambda_l1': 37.869580927344195, 'boosting_type': 'gbdt', 'n_estimators': 178, 'random_state': 276, 'verbose': -1}. Best is trial 4 with value: 0.6642022469498782.\n",
            "[I 2025-04-24 04:03:19,373] Trial 10 finished with value: 0.6641593252712114 and parameters: {'max_df': 0.6737531444663424, 'min_df': 0.011527777481819561, 'ngram_range': (2, 2), 'max_features': 7000, 'max_depth': 12, 'learning_rate': 0.09919798899643055, 'feature_fraction': 0.6782758665538365, 'bagging_fraction': 0.7004163587713501, 'lambda_l1': 97.9437242945835, 'boosting_type': 'gbdt', 'n_estimators': 357, 'random_state': 328, 'verbose': -1}. Best is trial 4 with value: 0.6642022469498782.\n",
            "[I 2025-04-24 04:04:19,009] Trial 11 finished with value: 0.6640049370790737 and parameters: {'max_df': 0.6631708891104293, 'min_df': 0.011990108203644781, 'ngram_range': (2, 2), 'max_features': 6750, 'max_depth': 12, 'learning_rate': 0.09503179035239287, 'feature_fraction': 0.6693356353947235, 'bagging_fraction': 0.6810931193734567, 'lambda_l1': 97.10344071846951, 'boosting_type': 'gbdt', 'n_estimators': 347, 'random_state': 329, 'verbose': -1}. Best is trial 4 with value: 0.6642022469498782.\n",
            "[I 2025-04-24 04:05:19,925] Trial 12 finished with value: 0.6690181559726944 and parameters: {'max_df': 0.6310491710600303, 'min_df': 0.011495948663913836, 'ngram_range': (2, 2), 'max_features': 5500, 'max_depth': 3, 'learning_rate': 0.01648268341293284, 'feature_fraction': 0.6874243090833333, 'bagging_fraction': 0.8090315315505091, 'lambda_l1': 73.01614427354367, 'boosting_type': 'gbdt', 'n_estimators': 348, 'random_state': 331, 'verbose': -1}. Best is trial 12 with value: 0.6690181559726944.\n",
            "[I 2025-04-24 04:06:19,275] Trial 13 finished with value: 0.6588820357813904 and parameters: {'max_df': 0.6234510301443817, 'min_df': 0.018185030930727146, 'ngram_range': (2, 2), 'max_features': 5500, 'max_depth': 3, 'learning_rate': 0.010823102552131064, 'feature_fraction': 0.616839502077653, 'bagging_fraction': 0.8519000015870504, 'lambda_l1': 71.62209964242496, 'boosting_type': 'gbdt', 'n_estimators': 303, 'random_state': 329, 'verbose': -1}. Best is trial 12 with value: 0.6690181559726944.\n",
            "[I 2025-04-24 04:07:19,193] Trial 14 finished with value: 0.6589546981407554 and parameters: {'max_df': 0.7548798131277865, 'min_df': 0.018245954714302494, 'ngram_range': (2, 2), 'max_features': 5500, 'max_depth': 3, 'learning_rate': 0.018827656213415804, 'feature_fraction': 0.743826264430104, 'bagging_fraction': 0.798632905290112, 'lambda_l1': 66.615427679889, 'boosting_type': 'gbdt', 'n_estimators': 412, 'random_state': 362, 'verbose': -1}. Best is trial 12 with value: 0.6690181559726944.\n",
            "[I 2025-04-24 04:08:18,905] Trial 15 finished with value: 0.658723508614171 and parameters: {'max_df': 0.6041721833481463, 'min_df': 0.01790866163954853, 'ngram_range': (2, 2), 'max_features': 4750, 'max_depth': 9, 'learning_rate': 0.011109945506620875, 'feature_fraction': 0.7370725621099607, 'bagging_fraction': 0.8715929374137268, 'lambda_l1': 76.37009779721168, 'boosting_type': 'gbdt', 'n_estimators': 247, 'random_state': 231, 'verbose': -1}. Best is trial 12 with value: 0.6690181559726944.\n",
            "[I 2025-04-24 04:09:19,423] Trial 16 finished with value: 0.6741158989598811 and parameters: {'max_df': 0.8554740833078559, 'min_df': 0.010552927610193177, 'ngram_range': (2, 2), 'max_features': 6250, 'max_depth': 4, 'learning_rate': 0.026822103429650364, 'feature_fraction': 0.60543585162445, 'bagging_fraction': 0.7369353601047084, 'lambda_l1': 64.44982066617848, 'boosting_type': 'gbdt', 'n_estimators': 320, 'random_state': 291, 'verbose': -1}. Best is trial 16 with value: 0.6741158989598811.\n",
            "[I 2025-04-24 04:10:20,049] Trial 17 finished with value: 0.6627400499146198 and parameters: {'max_df': 0.8994045096382094, 'min_df': 0.015437360344574904, 'ngram_range': (2, 2), 'max_features': 6250, 'max_depth': 4, 'learning_rate': 0.004687051934450539, 'feature_fraction': 0.5789010485610036, 'bagging_fraction': 0.7252991824564305, 'lambda_l1': 62.887554113169315, 'boosting_type': 'gbdt', 'n_estimators': 394, 'random_state': 293, 'verbose': -1}. Best is trial 16 with value: 0.6741158989598811.\n",
            "[I 2025-04-24 04:11:19,460] Trial 18 finished with value: 0.6580915043246301 and parameters: {'max_df': 0.7103909818167203, 'min_df': 0.022205065252223835, 'ngram_range': (2, 2), 'max_features': 4500, 'max_depth': 4, 'learning_rate': 1.1326119194740061e-05, 'feature_fraction': 0.6156348434639618, 'bagging_fraction': 0.622674134440173, 'lambda_l1': 50.29974472728453, 'boosting_type': 'gbdt', 'n_estimators': 303, 'random_state': 224, 'verbose': -1}. Best is trial 16 with value: 0.6741158989598811.\n",
            "[I 2025-04-24 04:12:46,572] Trial 19 finished with value: 0.7201854606688968 and parameters: {'max_df': 0.9994886539940573, 'min_df': 0.027208854263490973, 'ngram_range': (1, 2), 'max_features': 6000, 'max_depth': 5, 'learning_rate': 0.024147006611404682, 'feature_fraction': 0.5070121710891492, 'bagging_fraction': 0.9092920651878422, 'lambda_l1': 19.21524203380268, 'boosting_type': 'gbdt', 'n_estimators': 349, 'random_state': 296, 'verbose': -1}. Best is trial 19 with value: 0.7201854606688968.\n",
            "[I 2025-04-24 04:14:15,051] Trial 20 finished with value: 0.6246286232637878 and parameters: {'max_df': 0.9988465777601062, 'min_df': 0.03708825416757656, 'ngram_range': (1, 2), 'max_features': 5000, 'max_depth': 6, 'learning_rate': 0.00045897666009238786, 'feature_fraction': 0.516010769691053, 'bagging_fraction': 0.9020431686189906, 'lambda_l1': 16.826255643361534, 'boosting_type': 'gbdt', 'n_estimators': 428, 'random_state': 294, 'verbose': -1}. Best is trial 19 with value: 0.7201854606688968.\n",
            "[I 2025-04-24 04:15:36,323] Trial 21 finished with value: 0.6960234316885693 and parameters: {'max_df': 0.9216688769545067, 'min_df': 0.025829430378789868, 'ngram_range': (1, 2), 'max_features': 6000, 'max_depth': 4, 'learning_rate': 0.013319333942939963, 'feature_fraction': 0.6164504847894466, 'bagging_fraction': 0.9910022791797288, 'lambda_l1': 18.729028121835643, 'boosting_type': 'gbdt', 'n_estimators': 343, 'random_state': 301, 'verbose': -1}. Best is trial 19 with value: 0.7201854606688968.\n",
            "[I 2025-04-24 04:17:00,406] Trial 22 finished with value: 0.7172703427990964 and parameters: {'max_df': 0.9317026996701777, 'min_df': 0.0269014318277453, 'ngram_range': (1, 2), 'max_features': 6250, 'max_depth': 5, 'learning_rate': 0.025771143438666485, 'feature_fraction': 0.578532289929551, 'bagging_fraction': 0.989112067425829, 'lambda_l1': 11.79606501030687, 'boosting_type': 'gbdt', 'n_estimators': 289, 'random_state': 243, 'verbose': -1}. Best is trial 19 with value: 0.7201854606688968.\n",
            "[I 2025-04-24 04:18:26,675] Trial 23 finished with value: 0.6595749840356309 and parameters: {'max_df': 0.9369509496057207, 'min_df': 0.028409526254095926, 'ngram_range': (1, 2), 'max_features': 6000, 'max_depth': 5, 'learning_rate': 0.00672622647849321, 'feature_fraction': 0.5563625962431178, 'bagging_fraction': 0.9933598175009575, 'lambda_l1': 9.159557013839038, 'boosting_type': 'gbdt', 'n_estimators': 362, 'random_state': 238, 'verbose': -1}. Best is trial 19 with value: 0.7201854606688968.\n",
            "[I 2025-04-24 04:19:51,798] Trial 24 finished with value: 0.737432166497704 and parameters: {'max_df': 0.9494354551896035, 'min_df': 0.02462946689741808, 'ngram_range': (1, 2), 'max_features': 4000, 'max_depth': 6, 'learning_rate': 0.036761680478358136, 'feature_fraction': 0.5330728311986171, 'bagging_fraction': 0.9783841589731306, 'lambda_l1': 20.063407196623338, 'boosting_type': 'gbdt', 'n_estimators': 273, 'random_state': 255, 'verbose': -1}. Best is trial 24 with value: 0.737432166497704.\n"
          ]
        }
      ],
      "source": [
        "model_suggestions = {\n",
        "    'max_depth': lambda trial: trial.suggest_int('max_depth', 3, 12, step = 1),\n",
        "    'learning_rate': lambda trial: trial.suggest_float('learning_rate', 1e-5, 0.1, log = True),\n",
        "    'feature_fraction': lambda trial: trial.suggest_float('feature_fraction', 0.5, 1),\n",
        "    'bagging_fraction': lambda trial: trial.suggest_float('bagging_fraction', 0.5, 1),\n",
        "    'lambda_l1': lambda trial: trial.suggest_float('lambda_l1', 0, 100),\n",
        "    'lambda_l2': lambda trial: trial.suggest_float('lambda_l1', 0, 100),\n",
        "    'boosting_type': lambda trial: trial.suggest_categorical('boosting_type', ['gbdt']),\n",
        "    'n_estimators': lambda trial: trial.suggest_int('n_estimators', 100, 500, step = 1),\n",
        "    'random_state': lambda trial: trial.suggest_int('random_state', 100, 400, step = 1),\n",
        "    'verbose': lambda trial: trial.suggest_int('verbose', -1, -1, step = 1)\n",
        "}\n",
        "\n",
        "run_id = log_mlflow(tfidf_suggestions, model_suggestions, 'lgbm', X_train, y_train, X_val, y_val, X_test, y_test, 25, 'lightgbm', experiment_id = experiment_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ib9vyqrcmJE0"
      },
      "source": [
        "## Defining CatBoost Hyperparameter Search Space and Launching Optuna + MLflow Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-MyRS83jVhK"
      },
      "source": [
        "This section sets up a hyperparameter search space for CatBoost, a gradient boosting library optimized for performance and efficiency. We define key tuning parameters:\n",
        "\n",
        "- max_depth: Maximum depth of the trees.\n",
        "\n",
        "- learning_rate: Step size used to shrink each tree’s contribution (smaller = slower but more accurate learning).\n",
        "\n",
        "- l2_leaf_reg: L2 regularization to prevent overfitting by penalizing leaf scores.\n",
        "\n",
        "- bagging_temperature: Controls the amount of randomness in data sampling; higher = more randomness.\n",
        "\n",
        "- n_estimators: Total number of boosting rounds (trees).\n",
        "\n",
        "- random_state: Seed for reproducibility.\n",
        "\n",
        "- verbose: Set to 0 to suppress training output.\n",
        "\n",
        "We then call log_mlflow(...) to:\n",
        "\n",
        "- Optimize the CatBoost model over 25 trials using Optuna.\n",
        "\n",
        "- Automatically track the best trial, parameters, and performance metrics with MLflow.\n",
        "\n",
        "- Log model artifacts, evaluation plots (ROC, PR curves), and the trained pipeline for later analysis or deployment.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2ddEVz-mJ8A",
        "outputId": "b97d9acb-8b89-4f7a-d9c3-c9c046e2ae89"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-04 23:25:30,773] A new study created in memory with name: no-name-af156bfb-db13-498d-ac7d-3425677fc9c7\n",
            "[I 2025-05-04 23:27:27,852] Trial 0 finished with value: 0.5694221125181432 and parameters: {'max_df': 0.5911102674733995, 'min_df': 0.041955522682820524, 'ngram_range': (1, 2), 'max_features': 1000, 'max_depth': 3, 'learning_rate': 0.0015626453780787069, 'l2_leaf_reg': 61.0088772088764, 'bagging_temperature': 0.1374729603907443, 'n_estimators': 345, 'random_state': 145, 'verbose': 0}. Best is trial 0 with value: 0.5694221125181432.\n",
            "[I 2025-05-04 23:28:40,894] Trial 1 finished with value: 0.6569770335785607 and parameters: {'max_df': 0.7666792109441115, 'min_df': 0.024011779868490034, 'ngram_range': (2, 2), 'max_features': 3000, 'max_depth': 4, 'learning_rate': 0.014855037698110198, 'l2_leaf_reg': 41.38513738436608, 'bagging_temperature': 0.9788139085956903, 'n_estimators': 168, 'random_state': 133, 'verbose': 0}. Best is trial 1 with value: 0.6569770335785607.\n",
            "[I 2025-05-04 23:30:51,801] Trial 2 finished with value: 0.5959636678645864 and parameters: {'max_df': 0.9266931363919749, 'min_df': 0.02882328203617611, 'ngram_range': (1, 2), 'max_features': 4000, 'max_depth': 8, 'learning_rate': 2.844528956284961e-05, 'l2_leaf_reg': 63.952783994724086, 'bagging_temperature': 0.37018433896588143, 'n_estimators': 268, 'random_state': 156, 'verbose': 0}. Best is trial 1 with value: 0.6569770335785607.\n",
            "[I 2025-05-04 23:32:43,060] Trial 3 finished with value: 0.579275733461664 and parameters: {'max_df': 0.6299632964790947, 'min_df': 0.04757964744400911, 'ngram_range': (1, 2), 'max_features': 7000, 'max_depth': 8, 'learning_rate': 0.0003169769966359554, 'l2_leaf_reg': 59.15630119641529, 'bagging_temperature': 0.41236494848860383, 'n_estimators': 220, 'random_state': 243, 'verbose': 0}. Best is trial 1 with value: 0.6569770335785607.\n",
            "[I 2025-05-04 23:36:02,393] Trial 4 finished with value: 0.7570455612963832 and parameters: {'max_df': 0.5060706491352538, 'min_df': 0.02254020408399527, 'ngram_range': (1, 2), 'max_features': 5000, 'max_depth': 9, 'learning_rate': 0.03193805603442597, 'l2_leaf_reg': 2.088099691359326, 'bagging_temperature': 0.42942839370743113, 'n_estimators': 438, 'random_state': 234, 'verbose': 0}. Best is trial 4 with value: 0.7570455612963832.\n",
            "[I 2025-05-04 23:41:33,828] Trial 5 finished with value: 0.6591404303603877 and parameters: {'max_df': 0.7068980545723555, 'min_df': 0.01763561573329133, 'ngram_range': (1, 2), 'max_features': 6000, 'max_depth': 10, 'learning_rate': 0.002939772313491366, 'l2_leaf_reg': 84.54808896304706, 'bagging_temperature': 0.6672414153183484, 'n_estimators': 223, 'random_state': 355, 'verbose': 0}. Best is trial 4 with value: 0.7570455612963832.\n",
            "[I 2025-05-04 23:42:53,537] Trial 6 finished with value: 0.0953493806964244 and parameters: {'max_df': 0.8808979328768375, 'min_df': 0.04293922820293381, 'ngram_range': (2, 2), 'max_features': 4500, 'max_depth': 9, 'learning_rate': 2.6058796476654514e-05, 'l2_leaf_reg': 45.715952181587134, 'bagging_temperature': 0.7577008180971476, 'n_estimators': 438, 'random_state': 142, 'verbose': 0}. Best is trial 4 with value: 0.7570455612963832.\n",
            "[I 2025-05-04 23:44:05,519] Trial 7 finished with value: 0.0953493806964244 and parameters: {'max_df': 0.630904760830137, 'min_df': 0.04429417074967157, 'ngram_range': (2, 2), 'max_features': 4500, 'max_depth': 11, 'learning_rate': 0.0002623460373610999, 'l2_leaf_reg': 16.564100518287958, 'bagging_temperature': 0.42277269236635207, 'n_estimators': 110, 'random_state': 278, 'verbose': 0}. Best is trial 4 with value: 0.7570455612963832.\n",
            "[I 2025-05-04 23:49:34,110] Trial 8 finished with value: 0.6406781339760309 and parameters: {'max_df': 0.8283312899743529, 'min_df': 0.027049073695596434, 'ngram_range': (1, 1), 'max_features': 5750, 'max_depth': 11, 'learning_rate': 0.001217777882916908, 'l2_leaf_reg': 97.68314487502343, 'bagging_temperature': 0.7221949050588056, 'n_estimators': 383, 'random_state': 231, 'verbose': 0}. Best is trial 4 with value: 0.7570455612963832.\n",
            "[I 2025-05-04 23:50:29,017] Trial 9 finished with value: 0.5954198473282443 and parameters: {'max_df': 0.7644551165330694, 'min_df': 0.027956310940357325, 'ngram_range': (1, 1), 'max_features': 6250, 'max_depth': 7, 'learning_rate': 2.8302898493475382e-05, 'l2_leaf_reg': 86.4416595597376, 'bagging_temperature': 0.8924537278608701, 'n_estimators': 283, 'random_state': 180, 'verbose': 0}. Best is trial 4 with value: 0.7570455612963832.\n",
            "[I 2025-05-04 23:54:01,266] Trial 10 finished with value: 0.7994699010385906 and parameters: {'max_df': 0.5215093728163295, 'min_df': 0.013415530404284424, 'ngram_range': (1, 2), 'max_features': 1750, 'max_depth': 6, 'learning_rate': 0.09667102185171449, 'l2_leaf_reg': 1.8107375549879734, 'bagging_temperature': 0.11424526971296256, 'n_estimators': 475, 'random_state': 327, 'verbose': 0}. Best is trial 10 with value: 0.7994699010385906.\n",
            "[I 2025-05-04 23:58:07,969] Trial 11 finished with value: 0.8080445837487359 and parameters: {'max_df': 0.5010805225737633, 'min_df': 0.010197141993147023, 'ngram_range': (1, 2), 'max_features': 1000, 'max_depth': 6, 'learning_rate': 0.0993462716415053, 'l2_leaf_reg': 2.5129177027665706, 'bagging_temperature': 0.003603781334080569, 'n_estimators': 497, 'random_state': 337, 'verbose': 0}. Best is trial 11 with value: 0.8080445837487359.\n",
            "[I 2025-05-05 00:01:50,146] Trial 12 finished with value: 0.8017927283714372 and parameters: {'max_df': 0.5117835483897584, 'min_df': 0.012805891951044106, 'ngram_range': (1, 2), 'max_features': 1250, 'max_depth': 6, 'learning_rate': 0.09474668549164826, 'l2_leaf_reg': 21.11576708897613, 'bagging_temperature': 0.043305281306939114, 'n_estimators': 500, 'random_state': 375, 'verbose': 0}. Best is trial 11 with value: 0.8080445837487359.\n",
            "[I 2025-05-05 00:05:23,603] Trial 13 finished with value: 0.7369965808345185 and parameters: {'max_df': 0.56144906545789, 'min_df': 0.01237251021600128, 'ngram_range': (1, 2), 'max_features': 2500, 'max_depth': 5, 'learning_rate': 0.010239269842426903, 'l2_leaf_reg': 25.819340988183413, 'bagging_temperature': 0.0024197207395214725, 'n_estimators': 491, 'random_state': 399, 'verbose': 0}. Best is trial 11 with value: 0.8080445837487359.\n",
            "[I 2025-05-05 00:08:56,512] Trial 14 finished with value: 0.8006267925043667 and parameters: {'max_df': 0.6844612726100886, 'min_df': 0.010072987171058107, 'ngram_range': (1, 2), 'max_features': 1000, 'max_depth': 6, 'learning_rate': 0.07289922804333526, 'l2_leaf_reg': 20.830395822942823, 'bagging_temperature': 0.2243786452086769, 'n_estimators': 383, 'random_state': 306, 'verbose': 0}. Best is trial 11 with value: 0.8080445837487359.\n",
            "[I 2025-05-05 00:09:58,791] Trial 15 finished with value: 0.6655097136934022 and parameters: {'max_df': 0.999684870548551, 'min_df': 0.03540526654757086, 'ngram_range': (1, 1), 'max_features': 2750, 'max_depth': 5, 'learning_rate': 0.006613074197217099, 'l2_leaf_reg': 32.851052545957515, 'bagging_temperature': 0.25150653468929635, 'n_estimators': 495, 'random_state': 400, 'verbose': 0}. Best is trial 11 with value: 0.8080445837487359.\n",
            "[I 2025-05-05 00:12:50,981] Trial 16 finished with value: 0.761228793322606 and parameters: {'max_df': 0.5739188717258771, 'min_df': 0.017879333362721975, 'ngram_range': (1, 2), 'max_features': 1750, 'max_depth': 6, 'learning_rate': 0.02517596711048806, 'l2_leaf_reg': 12.738380918929913, 'bagging_temperature': 0.0050485861693444, 'n_estimators': 425, 'random_state': 354, 'verbose': 0}. Best is trial 11 with value: 0.8080445837487359.\n",
            "[I 2025-05-05 00:15:16,602] Trial 17 finished with value: 0.7490422168495443 and parameters: {'max_df': 0.6538430040704214, 'min_df': 0.017209370744952945, 'ngram_range': (1, 2), 'max_features': 1750, 'max_depth': 3, 'learning_rate': 0.04259357594393814, 'l2_leaf_reg': 33.8233213859429, 'bagging_temperature': 0.54679279765401, 'n_estimators': 340, 'random_state': 369, 'verbose': 0}. Best is trial 11 with value: 0.8080445837487359.\n",
            "[I 2025-05-05 00:16:18,631] Trial 18 finished with value: 0.6596714530050515 and parameters: {'max_df': 0.5025981489007209, 'min_df': 0.03290030456139488, 'ngram_range': (1, 1), 'max_features': 3750, 'max_depth': 7, 'learning_rate': 0.004640627490947738, 'l2_leaf_reg': 9.869222727005805, 'bagging_temperature': 0.22369664360725244, 'n_estimators': 391, 'random_state': 297, 'verbose': 0}. Best is trial 11 with value: 0.8080445837487359.\n",
            "[I 2025-05-05 00:17:46,940] Trial 19 finished with value: 0.6582638994091804 and parameters: {'max_df': 0.5604619903051312, 'min_df': 0.02116254334635073, 'ngram_range': (2, 2), 'max_features': 2250, 'max_depth': 5, 'learning_rate': 0.0002279276052729723, 'l2_leaf_reg': 24.898032088967483, 'bagging_temperature': 0.12578702886815796, 'n_estimators': 458, 'random_state': 321, 'verbose': 0}. Best is trial 11 with value: 0.8080445837487359.\n",
            "[I 2025-05-05 00:20:27,981] Trial 20 finished with value: 0.7827176771445337 and parameters: {'max_df': 0.7314085854758068, 'min_df': 0.014252730677435904, 'ngram_range': (1, 2), 'max_features': 3500, 'max_depth': 4, 'learning_rate': 0.09362620171982326, 'l2_leaf_reg': 8.691743312802323, 'bagging_temperature': 0.5555370035247507, 'n_estimators': 336, 'random_state': 272, 'verbose': 0}. Best is trial 11 with value: 0.8080445837487359.\n",
            "[I 2025-05-05 00:24:04,968] Trial 21 finished with value: 0.7941537351136774 and parameters: {'max_df': 0.6786238581492677, 'min_df': 0.010421615532947069, 'ngram_range': (1, 2), 'max_features': 1000, 'max_depth': 6, 'learning_rate': 0.05937069477850922, 'l2_leaf_reg': 20.026313126772028, 'bagging_temperature': 0.24226492434922797, 'n_estimators': 396, 'random_state': 325, 'verbose': 0}. Best is trial 11 with value: 0.8080445837487359.\n",
            "[I 2025-05-05 00:28:31,172] Trial 22 finished with value: 0.7809468359957789 and parameters: {'max_df': 0.8090195279902552, 'min_df': 0.010281638466749742, 'ngram_range': (1, 2), 'max_features': 1000, 'max_depth': 7, 'learning_rate': 0.023991568968014375, 'l2_leaf_reg': 32.69829095019735, 'bagging_temperature': 0.07919286519305294, 'n_estimators': 492, 'random_state': 370, 'verbose': 0}. Best is trial 11 with value: 0.8080445837487359.\n",
            "[I 2025-05-05 00:31:36,671] Trial 23 finished with value: 0.7907470533857176 and parameters: {'max_df': 0.617004612111309, 'min_df': 0.015995248218105516, 'ngram_range': (1, 2), 'max_features': 1500, 'max_depth': 6, 'learning_rate': 0.09617547755724545, 'l2_leaf_reg': 24.242618882159544, 'bagging_temperature': 0.19282543673277108, 'n_estimators': 417, 'random_state': 101, 'verbose': 0}. Best is trial 11 with value: 0.8080445837487359.\n",
            "[I 2025-05-05 00:34:26,353] Trial 24 finished with value: 0.738722382685022 and parameters: {'max_df': 0.5427061882379214, 'min_df': 0.02004001350495358, 'ngram_range': (1, 2), 'max_features': 2250, 'max_depth': 5, 'learning_rate': 0.015017151440655905, 'l2_leaf_reg': 7.755111758373676, 'bagging_temperature': 0.05441110333803195, 'n_estimators': 456, 'random_state': 304, 'verbose': 0}. Best is trial 11 with value: 0.8080445837487359.\n"
          ]
        }
      ],
      "source": [
        "model_suggestions = {\n",
        "    'max_depth': lambda trial: trial.suggest_int('max_depth', 3, 12, step = 1),\n",
        "    'learning_rate': lambda trial: trial.suggest_float('learning_rate', 1e-5, 0.1, log = True),\n",
        "    'l2_leaf_reg': lambda trial: trial.suggest_float('l2_leaf_reg', 1, 100),\n",
        "    'bagging_temperature': lambda trial: trial.suggest_float('bagging_temperature', 0, 1),\n",
        "    'n_estimators': lambda trial: trial.suggest_int('n_estimators', 100, 500, step = 1),\n",
        "    'random_state': lambda trial: trial.suggest_int('random_state', 100, 400, step = 1),\n",
        "    'verbose': lambda trial: trial.suggest_int('verbose', 0, 0, step = 1)\n",
        "}\n",
        "\n",
        "run_id = log_mlflow(tfidf_suggestions, model_suggestions, 'cat', X_train, y_train, X_val, y_val, X_test, y_test, 25, 'catboost', experiment_id = experiment_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f76Z4db_-3K-"
      },
      "source": [
        "## Loading the Best CatBoost Model and Evaluating on the Test Set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZERyeH41FjGF"
      },
      "source": [
        "Once the training and hyperparameter tuning are complete, we retrieve the best-performing CatBoost model using mlflow.search_runs() by filtering on the run name ('catboost') and sorting by validation F1 score.\n",
        "\n",
        "We then:\n",
        "\n",
        "- Load the model from the MLflow tracking server.\n",
        "\n",
        "- Generate predictions on the test set.\n",
        "\n",
        "- Print evaluation metrics, including Accuracy, Precision, Recall, Specificity, F1 Score, AUROC, and AUPRC.\n",
        "\n",
        "- Save the confusion matrix, ROC Curve, and Precision-Recall Curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GrBHR9WvluS4"
      },
      "outputs": [],
      "source": [
        "# search through mlflow runs and select the run with the best F1 score\n",
        "runs_df = mlflow.search_runs(\n",
        "    experiment_ids = [experiment_id],\n",
        "    filter_string = \"tags.mlflow.runName = 'catboost'\",\n",
        "    order_by = [\"metrics.val_f1 DESC\"]\n",
        ")\n",
        "\n",
        "best_run_id = runs_df.iloc[0][\"run_id\"]\n",
        "\n",
        "# load the model using the best run id\n",
        "model_uri = f\"runs:/{best_run_id}/catboost\"\n",
        "model = mlflow.sklearn.load_model(model_uri)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rcI7LxQZB9xR"
      },
      "outputs": [],
      "source": [
        "pred = model.predict(X_test)\n",
        "pred_proba = model.predict_proba(X_test)[:, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IqUyAIJKCMI5"
      },
      "outputs": [],
      "source": [
        "metrics = calculate_metrics(y_test, pred_proba, pred, set = 'test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2TXYhN9CQ_5",
        "outputId": "18391783-74da-4d06-bb70-2f7c0ebe3f2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.8092925\n",
            "Test Precision: 0.8118229431839377\n",
            "Test Recall: 0.805235\n",
            "Test Specificity: 0.81335\n",
            "Test F1: 0.808515551851638\n",
            "Test AUROC: 0.892993424675\n",
            "Test AUPRC: 0.8918270833481999\n"
          ]
        }
      ],
      "source": [
        "print('Test Accuracy:', metrics['test_accuracy'])\n",
        "print('Test Precision:', metrics['test_precision'])\n",
        "print('Test Recall:', metrics['test_recall'])\n",
        "print('Test Specificity:', metrics['test_specificity'])\n",
        "print('Test F1:', metrics['test_f1'])\n",
        "print('Test AUROC:', metrics['test_auroc'])\n",
        "print('Test AUPRC:', metrics['test_auprc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TcE3LfumDq2L"
      },
      "outputs": [],
      "source": [
        "create_confusion_matrix(y_test, pred, path = f'./artifacts/cat/test_confusion_matrix.png', set = 'Test')\n",
        "plot_roc_curve(y_test, pred_proba, path = f'./artifacts/cat/test_roc_curve.png', set = 'Test')\n",
        "plot_pr_curve(y_test, pred_proba, path = f'./artifacts/cat/test_pr_curve.png', set = 'Test')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
