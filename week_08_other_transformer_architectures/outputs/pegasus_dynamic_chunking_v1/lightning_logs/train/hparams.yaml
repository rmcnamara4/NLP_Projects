model_cfg:
  model_name: google/pegasus-pubmed
  dropout: 0.1
  attention_dropout: 0.1
  gradual_unfreeze: false
  max_unfrozen_layers: 0
lora_cfg:
  use_lora: true
  rank: 8
  alpha: 16
  target_modules:
  - q_proj
  - v_proj
  bias: none
  dropout: 0.1
optimizer_cfg:
  _target_: torch.optim.AdamW
  lr: 0.0001
  weight_decay: 0.001
scheduler_cfg:
  _target_: torch.optim.lr_scheduler.CosineAnnealingLR
  T_max: 10
  eta_min: 0.0
