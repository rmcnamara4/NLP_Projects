defaults: 
  - _self_
  - model: quantized
  - generation: default 
  - prompt: default 
  - data: default

run_name: 'mistral-7B-updated-extract'

hydra: 
  run: 
    dir: outputs/${run_name}/${prompt.prompt_version}

seed: 10

paths: 
  result_path: outputs/${run_name}/${prompt.prompt_version}